{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiabetesPrediction(ArtificialNeuralNetwork).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVijFjNo3mUWwU6w47H6Yp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GauravKakoti/Data-Science/blob/main/DiabetesPrediction(ArtificialNeuralNetwork).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUo46BM7ne1S"
      },
      "source": [
        "#Description: This program detects if a person has diabetes or not"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moiYMv1MolYz"
      },
      "source": [
        "#Load Libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqrISDa8pnWY",
        "outputId": "8b635162-ba10-42a7-d0a3-78560fcec251",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Load the Data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-64c3db68-171b-46d5-8872-862045a52ff6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-64c3db68-171b-46d5-8872-862045a52ff6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving datasets_228_482_diabetes.csv to datasets_228_482_diabetes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3l6kSZvqHcx",
        "outputId": "ca639ebb-5ba9-48e3-ff94-7fbf3b409049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#Store the data set\n",
        "df = pd.read_csv('datasets_228_482_diabetes.csv')\n",
        "\n",
        "#Print the first 7 rows odf data\n",
        "df.head(7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "5            5      116             74  ...                     0.201   30        0\n",
              "6            3       78             50  ...                     0.248   26        1\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ-9lUWfq1aj",
        "outputId": "13b2e4e4-9a05-470c-919b-89862c249296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Show the shape (No. of rows and columns)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ikexyOq__T"
      },
      "source": [
        "#Check for duplicacies and remove them\n",
        "df.drop_duplicates(inplace= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp5mO31rrQoK",
        "outputId": "8e3a45ee-56ea-442e-d06c-f656835e7c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Show the shape (No. of rows and columns)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ6J07w0rWJp",
        "outputId": "ae5d8ca7-556c-4b9e-8e8a-34813106d551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#show the no. of missing data for each column\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pregnancies                 0\n",
              "Glucose                     0\n",
              "BloodPressure               0\n",
              "SkinThickness               0\n",
              "Insulin                     0\n",
              "BMI                         0\n",
              "DiabetesPedigreeFunction    0\n",
              "Age                         0\n",
              "Outcome                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB2JCI8XriSk",
        "outputId": "d546ae2a-4169-42ae-ac43-344819990288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Convert the data into array\n",
        "dataset = df.values\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEq20VE7rugS"
      },
      "source": [
        "#Get all of the rows from the first eight columns of the dataset\n",
        "X = dataset[:, 0:8]\n",
        "Y = dataset[:, 8]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYt9EsfwsIPJ",
        "outputId": "9b8a93b5-4ebb-48e3-e380-465567c485f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Process the data\n",
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVuZRoE8s-8s"
      },
      "source": [
        "#Split the data into 80% training and 20% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scale,Y, test_size =0.2, random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngg-4KbvthtO"
      },
      "source": [
        "#Build the Model\n",
        "\n",
        "model = Sequential([\n",
        "             Dense(12, activation='relu', input_shape=(8,)),\n",
        "             Dense(15, activation='relu'),\n",
        "             Dense(1, activation='sigmoid')       \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVdMUhXQuNQk"
      },
      "source": [
        "#Compile the Model\n",
        "model.compile(\n",
        "    optimizer = 'sgd',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1INtm3tzu288",
        "outputId": "bf1002bb-c988-4e5d-dcc3-6706e69ba07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the Model\n",
        "hist = model.fit(X_train, Y_train, batch_size = 57, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 491 samples, validate on 123 samples\n",
            "Epoch 1/1000\n",
            "491/491 [==============================] - 0s 620us/step - loss: 0.6836 - accuracy: 0.6477 - val_loss: 0.6760 - val_accuracy: 0.6504\n",
            "Epoch 2/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6826 - accuracy: 0.6477 - val_loss: 0.6753 - val_accuracy: 0.6504\n",
            "Epoch 3/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6818 - accuracy: 0.6477 - val_loss: 0.6747 - val_accuracy: 0.6504\n",
            "Epoch 4/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6811 - accuracy: 0.6477 - val_loss: 0.6741 - val_accuracy: 0.6504\n",
            "Epoch 5/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6802 - accuracy: 0.6477 - val_loss: 0.6735 - val_accuracy: 0.6504\n",
            "Epoch 6/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6796 - accuracy: 0.6477 - val_loss: 0.6730 - val_accuracy: 0.6504\n",
            "Epoch 7/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6789 - accuracy: 0.6477 - val_loss: 0.6724 - val_accuracy: 0.6504\n",
            "Epoch 8/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6784 - accuracy: 0.6477 - val_loss: 0.6719 - val_accuracy: 0.6504\n",
            "Epoch 9/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6778 - accuracy: 0.6477 - val_loss: 0.6714 - val_accuracy: 0.6504\n",
            "Epoch 10/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6772 - accuracy: 0.6477 - val_loss: 0.6709 - val_accuracy: 0.6504\n",
            "Epoch 11/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6767 - accuracy: 0.6477 - val_loss: 0.6704 - val_accuracy: 0.6504\n",
            "Epoch 12/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6761 - accuracy: 0.6477 - val_loss: 0.6699 - val_accuracy: 0.6504\n",
            "Epoch 13/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6757 - accuracy: 0.6477 - val_loss: 0.6694 - val_accuracy: 0.6504\n",
            "Epoch 14/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6751 - accuracy: 0.6477 - val_loss: 0.6689 - val_accuracy: 0.6504\n",
            "Epoch 15/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6746 - accuracy: 0.6477 - val_loss: 0.6685 - val_accuracy: 0.6504\n",
            "Epoch 16/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6740 - accuracy: 0.6477 - val_loss: 0.6680 - val_accuracy: 0.6504\n",
            "Epoch 17/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6735 - accuracy: 0.6477 - val_loss: 0.6676 - val_accuracy: 0.6504\n",
            "Epoch 18/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6731 - accuracy: 0.6477 - val_loss: 0.6672 - val_accuracy: 0.6504\n",
            "Epoch 19/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6726 - accuracy: 0.6477 - val_loss: 0.6668 - val_accuracy: 0.6504\n",
            "Epoch 20/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6722 - accuracy: 0.6477 - val_loss: 0.6664 - val_accuracy: 0.6504\n",
            "Epoch 21/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6717 - accuracy: 0.6477 - val_loss: 0.6660 - val_accuracy: 0.6504\n",
            "Epoch 22/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6711 - accuracy: 0.6477 - val_loss: 0.6656 - val_accuracy: 0.6504\n",
            "Epoch 23/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6707 - accuracy: 0.6477 - val_loss: 0.6652 - val_accuracy: 0.6504\n",
            "Epoch 24/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6704 - accuracy: 0.6477 - val_loss: 0.6649 - val_accuracy: 0.6504\n",
            "Epoch 25/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6698 - accuracy: 0.6477 - val_loss: 0.6644 - val_accuracy: 0.6504\n",
            "Epoch 26/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6695 - accuracy: 0.6477 - val_loss: 0.6640 - val_accuracy: 0.6504\n",
            "Epoch 27/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6689 - accuracy: 0.6477 - val_loss: 0.6636 - val_accuracy: 0.6504\n",
            "Epoch 28/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6685 - accuracy: 0.6477 - val_loss: 0.6632 - val_accuracy: 0.6504\n",
            "Epoch 29/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6681 - accuracy: 0.6477 - val_loss: 0.6629 - val_accuracy: 0.6504\n",
            "Epoch 30/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6677 - accuracy: 0.6477 - val_loss: 0.6625 - val_accuracy: 0.6504\n",
            "Epoch 31/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6673 - accuracy: 0.6477 - val_loss: 0.6621 - val_accuracy: 0.6504\n",
            "Epoch 32/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6669 - accuracy: 0.6477 - val_loss: 0.6618 - val_accuracy: 0.6504\n",
            "Epoch 33/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6665 - accuracy: 0.6477 - val_loss: 0.6614 - val_accuracy: 0.6504\n",
            "Epoch 34/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6661 - accuracy: 0.6477 - val_loss: 0.6610 - val_accuracy: 0.6504\n",
            "Epoch 35/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.6656 - accuracy: 0.6477 - val_loss: 0.6607 - val_accuracy: 0.6504\n",
            "Epoch 36/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6653 - accuracy: 0.6477 - val_loss: 0.6604 - val_accuracy: 0.6504\n",
            "Epoch 37/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6648 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.6504\n",
            "Epoch 38/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6645 - accuracy: 0.6477 - val_loss: 0.6596 - val_accuracy: 0.6504\n",
            "Epoch 39/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6639 - accuracy: 0.6477 - val_loss: 0.6592 - val_accuracy: 0.6504\n",
            "Epoch 40/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6636 - accuracy: 0.6477 - val_loss: 0.6588 - val_accuracy: 0.6504\n",
            "Epoch 41/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.6634 - accuracy: 0.6477 - val_loss: 0.6585 - val_accuracy: 0.6504\n",
            "Epoch 42/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6628 - accuracy: 0.6477 - val_loss: 0.6582 - val_accuracy: 0.6504\n",
            "Epoch 43/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6624 - accuracy: 0.6477 - val_loss: 0.6578 - val_accuracy: 0.6504\n",
            "Epoch 44/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6620 - accuracy: 0.6477 - val_loss: 0.6575 - val_accuracy: 0.6504\n",
            "Epoch 45/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6616 - accuracy: 0.6477 - val_loss: 0.6571 - val_accuracy: 0.6504\n",
            "Epoch 46/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6612 - accuracy: 0.6477 - val_loss: 0.6568 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6608 - accuracy: 0.6477 - val_loss: 0.6564 - val_accuracy: 0.6504\n",
            "Epoch 48/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6606 - accuracy: 0.6477 - val_loss: 0.6561 - val_accuracy: 0.6504\n",
            "Epoch 49/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6601 - accuracy: 0.6477 - val_loss: 0.6558 - val_accuracy: 0.6504\n",
            "Epoch 50/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6596 - accuracy: 0.6477 - val_loss: 0.6554 - val_accuracy: 0.6504\n",
            "Epoch 51/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6593 - accuracy: 0.6477 - val_loss: 0.6551 - val_accuracy: 0.6504\n",
            "Epoch 52/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6589 - accuracy: 0.6477 - val_loss: 0.6548 - val_accuracy: 0.6504\n",
            "Epoch 53/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6585 - accuracy: 0.6477 - val_loss: 0.6544 - val_accuracy: 0.6504\n",
            "Epoch 54/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6581 - accuracy: 0.6477 - val_loss: 0.6541 - val_accuracy: 0.6504\n",
            "Epoch 55/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6578 - accuracy: 0.6477 - val_loss: 0.6538 - val_accuracy: 0.6504\n",
            "Epoch 56/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.6575 - accuracy: 0.6477 - val_loss: 0.6535 - val_accuracy: 0.6504\n",
            "Epoch 57/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6571 - accuracy: 0.6477 - val_loss: 0.6531 - val_accuracy: 0.6504\n",
            "Epoch 58/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6567 - accuracy: 0.6477 - val_loss: 0.6528 - val_accuracy: 0.6504\n",
            "Epoch 59/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6563 - accuracy: 0.6477 - val_loss: 0.6524 - val_accuracy: 0.6504\n",
            "Epoch 60/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6560 - accuracy: 0.6477 - val_loss: 0.6521 - val_accuracy: 0.6504\n",
            "Epoch 61/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6556 - accuracy: 0.6477 - val_loss: 0.6518 - val_accuracy: 0.6504\n",
            "Epoch 62/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6552 - accuracy: 0.6477 - val_loss: 0.6515 - val_accuracy: 0.6504\n",
            "Epoch 63/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6551 - accuracy: 0.6477 - val_loss: 0.6512 - val_accuracy: 0.6504\n",
            "Epoch 64/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6545 - accuracy: 0.6477 - val_loss: 0.6509 - val_accuracy: 0.6504\n",
            "Epoch 65/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6541 - accuracy: 0.6477 - val_loss: 0.6505 - val_accuracy: 0.6504\n",
            "Epoch 66/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6537 - accuracy: 0.6477 - val_loss: 0.6502 - val_accuracy: 0.6504\n",
            "Epoch 67/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6534 - accuracy: 0.6477 - val_loss: 0.6499 - val_accuracy: 0.6504\n",
            "Epoch 68/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6530 - accuracy: 0.6477 - val_loss: 0.6496 - val_accuracy: 0.6504\n",
            "Epoch 69/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6527 - accuracy: 0.6477 - val_loss: 0.6493 - val_accuracy: 0.6504\n",
            "Epoch 70/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6523 - accuracy: 0.6477 - val_loss: 0.6490 - val_accuracy: 0.6504\n",
            "Epoch 71/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6487 - val_accuracy: 0.6504\n",
            "Epoch 72/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6516 - accuracy: 0.6477 - val_loss: 0.6484 - val_accuracy: 0.6504\n",
            "Epoch 73/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6515 - accuracy: 0.6477 - val_loss: 0.6481 - val_accuracy: 0.6504\n",
            "Epoch 74/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6509 - accuracy: 0.6477 - val_loss: 0.6478 - val_accuracy: 0.6504\n",
            "Epoch 75/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6506 - accuracy: 0.6477 - val_loss: 0.6475 - val_accuracy: 0.6504\n",
            "Epoch 76/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6502 - accuracy: 0.6477 - val_loss: 0.6472 - val_accuracy: 0.6504\n",
            "Epoch 77/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6498 - accuracy: 0.6477 - val_loss: 0.6468 - val_accuracy: 0.6504\n",
            "Epoch 78/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6494 - accuracy: 0.6477 - val_loss: 0.6465 - val_accuracy: 0.6504\n",
            "Epoch 79/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6491 - accuracy: 0.6477 - val_loss: 0.6462 - val_accuracy: 0.6504\n",
            "Epoch 80/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6489 - accuracy: 0.6477 - val_loss: 0.6459 - val_accuracy: 0.6504\n",
            "Epoch 81/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6484 - accuracy: 0.6477 - val_loss: 0.6456 - val_accuracy: 0.6504\n",
            "Epoch 82/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6481 - accuracy: 0.6477 - val_loss: 0.6452 - val_accuracy: 0.6504\n",
            "Epoch 83/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6476 - accuracy: 0.6477 - val_loss: 0.6449 - val_accuracy: 0.6504\n",
            "Epoch 84/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6473 - accuracy: 0.6477 - val_loss: 0.6446 - val_accuracy: 0.6504\n",
            "Epoch 85/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.6470 - accuracy: 0.6477 - val_loss: 0.6443 - val_accuracy: 0.6504\n",
            "Epoch 86/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6467 - accuracy: 0.6477 - val_loss: 0.6440 - val_accuracy: 0.6504\n",
            "Epoch 87/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6463 - accuracy: 0.6477 - val_loss: 0.6437 - val_accuracy: 0.6504\n",
            "Epoch 88/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6459 - accuracy: 0.6477 - val_loss: 0.6434 - val_accuracy: 0.6504\n",
            "Epoch 89/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6456 - accuracy: 0.6477 - val_loss: 0.6431 - val_accuracy: 0.6504\n",
            "Epoch 90/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6453 - accuracy: 0.6477 - val_loss: 0.6428 - val_accuracy: 0.6504\n",
            "Epoch 91/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6449 - accuracy: 0.6477 - val_loss: 0.6425 - val_accuracy: 0.6504\n",
            "Epoch 92/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6445 - accuracy: 0.6477 - val_loss: 0.6422 - val_accuracy: 0.6504\n",
            "Epoch 93/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6443 - accuracy: 0.6477 - val_loss: 0.6418 - val_accuracy: 0.6504\n",
            "Epoch 94/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6439 - accuracy: 0.6477 - val_loss: 0.6415 - val_accuracy: 0.6504\n",
            "Epoch 95/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6435 - accuracy: 0.6477 - val_loss: 0.6412 - val_accuracy: 0.6504\n",
            "Epoch 96/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6432 - accuracy: 0.6477 - val_loss: 0.6409 - val_accuracy: 0.6504\n",
            "Epoch 97/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6427 - accuracy: 0.6477 - val_loss: 0.6406 - val_accuracy: 0.6504\n",
            "Epoch 98/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6423 - accuracy: 0.6477 - val_loss: 0.6403 - val_accuracy: 0.6504\n",
            "Epoch 99/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6421 - accuracy: 0.6477 - val_loss: 0.6400 - val_accuracy: 0.6504\n",
            "Epoch 100/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6417 - accuracy: 0.6477 - val_loss: 0.6397 - val_accuracy: 0.6504\n",
            "Epoch 101/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6414 - accuracy: 0.6477 - val_loss: 0.6393 - val_accuracy: 0.6504\n",
            "Epoch 102/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6410 - accuracy: 0.6477 - val_loss: 0.6390 - val_accuracy: 0.6504\n",
            "Epoch 103/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6407 - accuracy: 0.6477 - val_loss: 0.6387 - val_accuracy: 0.6504\n",
            "Epoch 104/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6402 - accuracy: 0.6477 - val_loss: 0.6384 - val_accuracy: 0.6504\n",
            "Epoch 105/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6399 - accuracy: 0.6477 - val_loss: 0.6381 - val_accuracy: 0.6504\n",
            "Epoch 106/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6396 - accuracy: 0.6477 - val_loss: 0.6378 - val_accuracy: 0.6504\n",
            "Epoch 107/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6393 - accuracy: 0.6477 - val_loss: 0.6375 - val_accuracy: 0.6504\n",
            "Epoch 108/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6388 - accuracy: 0.6477 - val_loss: 0.6372 - val_accuracy: 0.6504\n",
            "Epoch 109/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6385 - accuracy: 0.6477 - val_loss: 0.6369 - val_accuracy: 0.6504\n",
            "Epoch 110/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6381 - accuracy: 0.6477 - val_loss: 0.6365 - val_accuracy: 0.6504\n",
            "Epoch 111/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6378 - accuracy: 0.6477 - val_loss: 0.6363 - val_accuracy: 0.6504\n",
            "Epoch 112/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6374 - accuracy: 0.6477 - val_loss: 0.6359 - val_accuracy: 0.6504\n",
            "Epoch 113/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.6371 - accuracy: 0.6477 - val_loss: 0.6356 - val_accuracy: 0.6504\n",
            "Epoch 114/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6367 - accuracy: 0.6477 - val_loss: 0.6353 - val_accuracy: 0.6504\n",
            "Epoch 115/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.6364 - accuracy: 0.6477 - val_loss: 0.6349 - val_accuracy: 0.6504\n",
            "Epoch 116/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.6360 - accuracy: 0.6477 - val_loss: 0.6347 - val_accuracy: 0.6504\n",
            "Epoch 117/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6357 - accuracy: 0.6477 - val_loss: 0.6343 - val_accuracy: 0.6504\n",
            "Epoch 118/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6353 - accuracy: 0.6477 - val_loss: 0.6340 - val_accuracy: 0.6504\n",
            "Epoch 119/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6349 - accuracy: 0.6477 - val_loss: 0.6337 - val_accuracy: 0.6504\n",
            "Epoch 120/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6347 - accuracy: 0.6477 - val_loss: 0.6333 - val_accuracy: 0.6504\n",
            "Epoch 121/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6341 - accuracy: 0.6477 - val_loss: 0.6330 - val_accuracy: 0.6504\n",
            "Epoch 122/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6338 - accuracy: 0.6477 - val_loss: 0.6327 - val_accuracy: 0.6504\n",
            "Epoch 123/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6334 - accuracy: 0.6477 - val_loss: 0.6324 - val_accuracy: 0.6504\n",
            "Epoch 124/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6330 - accuracy: 0.6477 - val_loss: 0.6321 - val_accuracy: 0.6504\n",
            "Epoch 125/1000\n",
            "491/491 [==============================] - 0s 55us/step - loss: 0.6327 - accuracy: 0.6477 - val_loss: 0.6317 - val_accuracy: 0.6504\n",
            "Epoch 126/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6324 - accuracy: 0.6477 - val_loss: 0.6314 - val_accuracy: 0.6504\n",
            "Epoch 127/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6319 - accuracy: 0.6477 - val_loss: 0.6311 - val_accuracy: 0.6504\n",
            "Epoch 128/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6316 - accuracy: 0.6477 - val_loss: 0.6308 - val_accuracy: 0.6504\n",
            "Epoch 129/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6312 - accuracy: 0.6477 - val_loss: 0.6305 - val_accuracy: 0.6504\n",
            "Epoch 130/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6308 - accuracy: 0.6477 - val_loss: 0.6302 - val_accuracy: 0.6504\n",
            "Epoch 131/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6304 - accuracy: 0.6477 - val_loss: 0.6298 - val_accuracy: 0.6504\n",
            "Epoch 132/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6300 - accuracy: 0.6477 - val_loss: 0.6295 - val_accuracy: 0.6504\n",
            "Epoch 133/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6296 - accuracy: 0.6477 - val_loss: 0.6292 - val_accuracy: 0.6504\n",
            "Epoch 134/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6293 - accuracy: 0.6477 - val_loss: 0.6288 - val_accuracy: 0.6504\n",
            "Epoch 135/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.6290 - accuracy: 0.6477 - val_loss: 0.6286 - val_accuracy: 0.6504\n",
            "Epoch 136/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6284 - accuracy: 0.6477 - val_loss: 0.6282 - val_accuracy: 0.6504\n",
            "Epoch 137/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6281 - accuracy: 0.6477 - val_loss: 0.6279 - val_accuracy: 0.6504\n",
            "Epoch 138/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6277 - accuracy: 0.6477 - val_loss: 0.6275 - val_accuracy: 0.6504\n",
            "Epoch 139/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6273 - accuracy: 0.6477 - val_loss: 0.6272 - val_accuracy: 0.6504\n",
            "Epoch 140/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6269 - accuracy: 0.6477 - val_loss: 0.6268 - val_accuracy: 0.6504\n",
            "Epoch 141/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6265 - accuracy: 0.6477 - val_loss: 0.6265 - val_accuracy: 0.6504\n",
            "Epoch 142/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6262 - accuracy: 0.6477 - val_loss: 0.6261 - val_accuracy: 0.6504\n",
            "Epoch 143/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6257 - accuracy: 0.6477 - val_loss: 0.6258 - val_accuracy: 0.6504\n",
            "Epoch 144/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6253 - accuracy: 0.6477 - val_loss: 0.6255 - val_accuracy: 0.6504\n",
            "Epoch 145/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6249 - accuracy: 0.6477 - val_loss: 0.6251 - val_accuracy: 0.6504\n",
            "Epoch 146/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6245 - accuracy: 0.6477 - val_loss: 0.6248 - val_accuracy: 0.6504\n",
            "Epoch 147/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6242 - accuracy: 0.6477 - val_loss: 0.6244 - val_accuracy: 0.6504\n",
            "Epoch 148/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6237 - accuracy: 0.6477 - val_loss: 0.6241 - val_accuracy: 0.6504\n",
            "Epoch 149/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6234 - accuracy: 0.6477 - val_loss: 0.6237 - val_accuracy: 0.6504\n",
            "Epoch 150/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6230 - accuracy: 0.6477 - val_loss: 0.6234 - val_accuracy: 0.6504\n",
            "Epoch 151/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6225 - accuracy: 0.6477 - val_loss: 0.6230 - val_accuracy: 0.6504\n",
            "Epoch 152/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6222 - accuracy: 0.6477 - val_loss: 0.6227 - val_accuracy: 0.6504\n",
            "Epoch 153/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6219 - accuracy: 0.6477 - val_loss: 0.6223 - val_accuracy: 0.6504\n",
            "Epoch 154/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6214 - accuracy: 0.6477 - val_loss: 0.6220 - val_accuracy: 0.6504\n",
            "Epoch 155/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6210 - accuracy: 0.6477 - val_loss: 0.6216 - val_accuracy: 0.6504\n",
            "Epoch 156/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6206 - accuracy: 0.6477 - val_loss: 0.6212 - val_accuracy: 0.6504\n",
            "Epoch 157/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6201 - accuracy: 0.6477 - val_loss: 0.6209 - val_accuracy: 0.6504\n",
            "Epoch 158/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6197 - accuracy: 0.6477 - val_loss: 0.6205 - val_accuracy: 0.6504\n",
            "Epoch 159/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6193 - accuracy: 0.6477 - val_loss: 0.6201 - val_accuracy: 0.6504\n",
            "Epoch 160/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6188 - accuracy: 0.6477 - val_loss: 0.6198 - val_accuracy: 0.6504\n",
            "Epoch 161/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6186 - accuracy: 0.6477 - val_loss: 0.6194 - val_accuracy: 0.6504\n",
            "Epoch 162/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6180 - accuracy: 0.6477 - val_loss: 0.6191 - val_accuracy: 0.6504\n",
            "Epoch 163/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6177 - accuracy: 0.6477 - val_loss: 0.6187 - val_accuracy: 0.6504\n",
            "Epoch 164/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6172 - accuracy: 0.6477 - val_loss: 0.6184 - val_accuracy: 0.6504\n",
            "Epoch 165/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6168 - accuracy: 0.6477 - val_loss: 0.6181 - val_accuracy: 0.6504\n",
            "Epoch 166/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6163 - accuracy: 0.6497 - val_loss: 0.6177 - val_accuracy: 0.6504\n",
            "Epoch 167/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6161 - accuracy: 0.6477 - val_loss: 0.6173 - val_accuracy: 0.6504\n",
            "Epoch 168/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6156 - accuracy: 0.6497 - val_loss: 0.6169 - val_accuracy: 0.6504\n",
            "Epoch 169/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6151 - accuracy: 0.6497 - val_loss: 0.6165 - val_accuracy: 0.6504\n",
            "Epoch 170/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6147 - accuracy: 0.6497 - val_loss: 0.6161 - val_accuracy: 0.6504\n",
            "Epoch 171/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6143 - accuracy: 0.6497 - val_loss: 0.6157 - val_accuracy: 0.6504\n",
            "Epoch 172/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6139 - accuracy: 0.6497 - val_loss: 0.6153 - val_accuracy: 0.6504\n",
            "Epoch 173/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6133 - accuracy: 0.6497 - val_loss: 0.6150 - val_accuracy: 0.6504\n",
            "Epoch 174/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6130 - accuracy: 0.6497 - val_loss: 0.6146 - val_accuracy: 0.6504\n",
            "Epoch 175/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6124 - accuracy: 0.6497 - val_loss: 0.6142 - val_accuracy: 0.6504\n",
            "Epoch 176/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6122 - accuracy: 0.6497 - val_loss: 0.6138 - val_accuracy: 0.6504\n",
            "Epoch 177/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6116 - accuracy: 0.6497 - val_loss: 0.6134 - val_accuracy: 0.6504\n",
            "Epoch 178/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6111 - accuracy: 0.6497 - val_loss: 0.6130 - val_accuracy: 0.6504\n",
            "Epoch 179/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.6107 - accuracy: 0.6517 - val_loss: 0.6127 - val_accuracy: 0.6585\n",
            "Epoch 180/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.6101 - accuracy: 0.6497 - val_loss: 0.6123 - val_accuracy: 0.6585\n",
            "Epoch 181/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6097 - accuracy: 0.6497 - val_loss: 0.6119 - val_accuracy: 0.6585\n",
            "Epoch 182/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6092 - accuracy: 0.6497 - val_loss: 0.6115 - val_accuracy: 0.6585\n",
            "Epoch 183/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6089 - accuracy: 0.6558 - val_loss: 0.6112 - val_accuracy: 0.6585\n",
            "Epoch 184/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6084 - accuracy: 0.6517 - val_loss: 0.6108 - val_accuracy: 0.6585\n",
            "Epoch 185/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.6079 - accuracy: 0.6599 - val_loss: 0.6104 - val_accuracy: 0.6585\n",
            "Epoch 186/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.6075 - accuracy: 0.6619 - val_loss: 0.6100 - val_accuracy: 0.6585\n",
            "Epoch 187/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6069 - accuracy: 0.6599 - val_loss: 0.6096 - val_accuracy: 0.6585\n",
            "Epoch 188/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6066 - accuracy: 0.6619 - val_loss: 0.6091 - val_accuracy: 0.6585\n",
            "Epoch 189/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6062 - accuracy: 0.6599 - val_loss: 0.6087 - val_accuracy: 0.6585\n",
            "Epoch 190/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6056 - accuracy: 0.6619 - val_loss: 0.6083 - val_accuracy: 0.6585\n",
            "Epoch 191/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6052 - accuracy: 0.6619 - val_loss: 0.6079 - val_accuracy: 0.6585\n",
            "Epoch 192/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.6046 - accuracy: 0.6619 - val_loss: 0.6075 - val_accuracy: 0.6585\n",
            "Epoch 193/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6043 - accuracy: 0.6619 - val_loss: 0.6071 - val_accuracy: 0.6585\n",
            "Epoch 194/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.6036 - accuracy: 0.6640 - val_loss: 0.6067 - val_accuracy: 0.6585\n",
            "Epoch 195/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.6032 - accuracy: 0.6619 - val_loss: 0.6063 - val_accuracy: 0.6585\n",
            "Epoch 196/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.6027 - accuracy: 0.6599 - val_loss: 0.6059 - val_accuracy: 0.6585\n",
            "Epoch 197/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.6023 - accuracy: 0.6619 - val_loss: 0.6055 - val_accuracy: 0.6504\n",
            "Epoch 198/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.6018 - accuracy: 0.6619 - val_loss: 0.6051 - val_accuracy: 0.6504\n",
            "Epoch 199/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.6013 - accuracy: 0.6619 - val_loss: 0.6047 - val_accuracy: 0.6504\n",
            "Epoch 200/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.6010 - accuracy: 0.6619 - val_loss: 0.6042 - val_accuracy: 0.6504\n",
            "Epoch 201/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.6002 - accuracy: 0.6619 - val_loss: 0.6038 - val_accuracy: 0.6504\n",
            "Epoch 202/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.6000 - accuracy: 0.6619 - val_loss: 0.6034 - val_accuracy: 0.6504\n",
            "Epoch 203/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5994 - accuracy: 0.6619 - val_loss: 0.6030 - val_accuracy: 0.6504\n",
            "Epoch 204/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5988 - accuracy: 0.6619 - val_loss: 0.6026 - val_accuracy: 0.6504\n",
            "Epoch 205/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5984 - accuracy: 0.6619 - val_loss: 0.6022 - val_accuracy: 0.6504\n",
            "Epoch 206/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5979 - accuracy: 0.6680 - val_loss: 0.6017 - val_accuracy: 0.6504\n",
            "Epoch 207/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5973 - accuracy: 0.6619 - val_loss: 0.6013 - val_accuracy: 0.6585\n",
            "Epoch 208/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5968 - accuracy: 0.6640 - val_loss: 0.6009 - val_accuracy: 0.6585\n",
            "Epoch 209/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5964 - accuracy: 0.6680 - val_loss: 0.6005 - val_accuracy: 0.6585\n",
            "Epoch 210/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5961 - accuracy: 0.6721 - val_loss: 0.6000 - val_accuracy: 0.6585\n",
            "Epoch 211/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5955 - accuracy: 0.6721 - val_loss: 0.5996 - val_accuracy: 0.6585\n",
            "Epoch 212/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5948 - accuracy: 0.6721 - val_loss: 0.5992 - val_accuracy: 0.6585\n",
            "Epoch 213/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5945 - accuracy: 0.6701 - val_loss: 0.5987 - val_accuracy: 0.6585\n",
            "Epoch 214/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5938 - accuracy: 0.6721 - val_loss: 0.5983 - val_accuracy: 0.6585\n",
            "Epoch 215/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5933 - accuracy: 0.6721 - val_loss: 0.5979 - val_accuracy: 0.6667\n",
            "Epoch 216/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5929 - accuracy: 0.6701 - val_loss: 0.5975 - val_accuracy: 0.6667\n",
            "Epoch 217/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5922 - accuracy: 0.6782 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
            "Epoch 218/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5918 - accuracy: 0.6741 - val_loss: 0.5966 - val_accuracy: 0.6667\n",
            "Epoch 219/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5912 - accuracy: 0.6782 - val_loss: 0.5962 - val_accuracy: 0.6667\n",
            "Epoch 220/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5908 - accuracy: 0.6802 - val_loss: 0.5957 - val_accuracy: 0.6667\n",
            "Epoch 221/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5902 - accuracy: 0.6802 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
            "Epoch 222/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5896 - accuracy: 0.6802 - val_loss: 0.5948 - val_accuracy: 0.6585\n",
            "Epoch 223/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5893 - accuracy: 0.6823 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
            "Epoch 224/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5886 - accuracy: 0.6802 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
            "Epoch 225/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5881 - accuracy: 0.6864 - val_loss: 0.5934 - val_accuracy: 0.6585\n",
            "Epoch 226/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5876 - accuracy: 0.6823 - val_loss: 0.5930 - val_accuracy: 0.6585\n",
            "Epoch 227/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5872 - accuracy: 0.6802 - val_loss: 0.5925 - val_accuracy: 0.6585\n",
            "Epoch 228/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5865 - accuracy: 0.6823 - val_loss: 0.5921 - val_accuracy: 0.6585\n",
            "Epoch 229/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5859 - accuracy: 0.6925 - val_loss: 0.5916 - val_accuracy: 0.6585\n",
            "Epoch 230/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5854 - accuracy: 0.6904 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
            "Epoch 231/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5849 - accuracy: 0.6925 - val_loss: 0.5907 - val_accuracy: 0.6585\n",
            "Epoch 232/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5843 - accuracy: 0.6904 - val_loss: 0.5903 - val_accuracy: 0.6667\n",
            "Epoch 233/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5838 - accuracy: 0.6945 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
            "Epoch 234/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5833 - accuracy: 0.6965 - val_loss: 0.5894 - val_accuracy: 0.6748\n",
            "Epoch 235/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5827 - accuracy: 0.6945 - val_loss: 0.5890 - val_accuracy: 0.6748\n",
            "Epoch 236/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5823 - accuracy: 0.6945 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
            "Epoch 237/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5816 - accuracy: 0.6945 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
            "Epoch 238/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5811 - accuracy: 0.7026 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
            "Epoch 239/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5807 - accuracy: 0.7006 - val_loss: 0.5871 - val_accuracy: 0.6667\n",
            "Epoch 240/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.5800 - accuracy: 0.7006 - val_loss: 0.5866 - val_accuracy: 0.6585\n",
            "Epoch 241/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5795 - accuracy: 0.6965 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
            "Epoch 242/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5788 - accuracy: 0.7006 - val_loss: 0.5857 - val_accuracy: 0.6667\n",
            "Epoch 243/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5784 - accuracy: 0.7047 - val_loss: 0.5853 - val_accuracy: 0.6667\n",
            "Epoch 244/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5779 - accuracy: 0.7088 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
            "Epoch 245/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5773 - accuracy: 0.7128 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
            "Epoch 246/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5768 - accuracy: 0.7128 - val_loss: 0.5839 - val_accuracy: 0.6667\n",
            "Epoch 247/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5762 - accuracy: 0.7128 - val_loss: 0.5835 - val_accuracy: 0.6667\n",
            "Epoch 248/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5756 - accuracy: 0.7149 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
            "Epoch 249/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5755 - accuracy: 0.7149 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
            "Epoch 250/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5745 - accuracy: 0.7149 - val_loss: 0.5821 - val_accuracy: 0.6667\n",
            "Epoch 251/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5743 - accuracy: 0.7149 - val_loss: 0.5817 - val_accuracy: 0.6667\n",
            "Epoch 252/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5736 - accuracy: 0.7169 - val_loss: 0.5812 - val_accuracy: 0.6748\n",
            "Epoch 253/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5730 - accuracy: 0.7149 - val_loss: 0.5807 - val_accuracy: 0.6748\n",
            "Epoch 254/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5723 - accuracy: 0.7149 - val_loss: 0.5803 - val_accuracy: 0.6829\n",
            "Epoch 255/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5718 - accuracy: 0.7230 - val_loss: 0.5799 - val_accuracy: 0.6829\n",
            "Epoch 256/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5712 - accuracy: 0.7169 - val_loss: 0.5794 - val_accuracy: 0.6829\n",
            "Epoch 257/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5710 - accuracy: 0.7149 - val_loss: 0.5790 - val_accuracy: 0.6829\n",
            "Epoch 258/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5702 - accuracy: 0.7251 - val_loss: 0.5785 - val_accuracy: 0.6829\n",
            "Epoch 259/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5698 - accuracy: 0.7210 - val_loss: 0.5781 - val_accuracy: 0.6829\n",
            "Epoch 260/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5691 - accuracy: 0.7251 - val_loss: 0.5777 - val_accuracy: 0.6829\n",
            "Epoch 261/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5686 - accuracy: 0.7230 - val_loss: 0.5773 - val_accuracy: 0.6911\n",
            "Epoch 262/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5681 - accuracy: 0.7251 - val_loss: 0.5768 - val_accuracy: 0.6911\n",
            "Epoch 263/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5674 - accuracy: 0.7291 - val_loss: 0.5764 - val_accuracy: 0.6911\n",
            "Epoch 264/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5674 - accuracy: 0.7312 - val_loss: 0.5759 - val_accuracy: 0.6911\n",
            "Epoch 265/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5664 - accuracy: 0.7312 - val_loss: 0.5754 - val_accuracy: 0.6911\n",
            "Epoch 266/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5658 - accuracy: 0.7271 - val_loss: 0.5750 - val_accuracy: 0.6911\n",
            "Epoch 267/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5653 - accuracy: 0.7291 - val_loss: 0.5746 - val_accuracy: 0.6911\n",
            "Epoch 268/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5647 - accuracy: 0.7291 - val_loss: 0.5742 - val_accuracy: 0.6911\n",
            "Epoch 269/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5642 - accuracy: 0.7312 - val_loss: 0.5737 - val_accuracy: 0.6911\n",
            "Epoch 270/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5636 - accuracy: 0.7312 - val_loss: 0.5733 - val_accuracy: 0.6992\n",
            "Epoch 271/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5631 - accuracy: 0.7271 - val_loss: 0.5728 - val_accuracy: 0.6911\n",
            "Epoch 272/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5627 - accuracy: 0.7291 - val_loss: 0.5724 - val_accuracy: 0.6992\n",
            "Epoch 273/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5620 - accuracy: 0.7291 - val_loss: 0.5720 - val_accuracy: 0.6992\n",
            "Epoch 274/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5616 - accuracy: 0.7251 - val_loss: 0.5716 - val_accuracy: 0.7073\n",
            "Epoch 275/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5611 - accuracy: 0.7271 - val_loss: 0.5711 - val_accuracy: 0.7073\n",
            "Epoch 276/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5605 - accuracy: 0.7230 - val_loss: 0.5707 - val_accuracy: 0.7073\n",
            "Epoch 277/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5598 - accuracy: 0.7271 - val_loss: 0.5703 - val_accuracy: 0.7073\n",
            "Epoch 278/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5596 - accuracy: 0.7291 - val_loss: 0.5699 - val_accuracy: 0.7073\n",
            "Epoch 279/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5587 - accuracy: 0.7271 - val_loss: 0.5694 - val_accuracy: 0.7073\n",
            "Epoch 280/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5583 - accuracy: 0.7251 - val_loss: 0.5690 - val_accuracy: 0.7073\n",
            "Epoch 281/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5578 - accuracy: 0.7271 - val_loss: 0.5686 - val_accuracy: 0.7073\n",
            "Epoch 282/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5574 - accuracy: 0.7271 - val_loss: 0.5682 - val_accuracy: 0.7154\n",
            "Epoch 283/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5567 - accuracy: 0.7312 - val_loss: 0.5679 - val_accuracy: 0.7154\n",
            "Epoch 284/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5563 - accuracy: 0.7332 - val_loss: 0.5674 - val_accuracy: 0.7154\n",
            "Epoch 285/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5557 - accuracy: 0.7271 - val_loss: 0.5670 - val_accuracy: 0.7154\n",
            "Epoch 286/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5551 - accuracy: 0.7271 - val_loss: 0.5665 - val_accuracy: 0.7154\n",
            "Epoch 287/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5547 - accuracy: 0.7291 - val_loss: 0.5660 - val_accuracy: 0.7154\n",
            "Epoch 288/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5541 - accuracy: 0.7332 - val_loss: 0.5657 - val_accuracy: 0.7154\n",
            "Epoch 289/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5536 - accuracy: 0.7332 - val_loss: 0.5653 - val_accuracy: 0.7154\n",
            "Epoch 290/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5531 - accuracy: 0.7291 - val_loss: 0.5649 - val_accuracy: 0.7154\n",
            "Epoch 291/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5524 - accuracy: 0.7312 - val_loss: 0.5645 - val_accuracy: 0.7154\n",
            "Epoch 292/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5519 - accuracy: 0.7271 - val_loss: 0.5641 - val_accuracy: 0.7154\n",
            "Epoch 293/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.5514 - accuracy: 0.7251 - val_loss: 0.5637 - val_accuracy: 0.7154\n",
            "Epoch 294/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5510 - accuracy: 0.7271 - val_loss: 0.5632 - val_accuracy: 0.7154\n",
            "Epoch 295/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5505 - accuracy: 0.7251 - val_loss: 0.5628 - val_accuracy: 0.7154\n",
            "Epoch 296/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5500 - accuracy: 0.7251 - val_loss: 0.5624 - val_accuracy: 0.7236\n",
            "Epoch 297/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5496 - accuracy: 0.7291 - val_loss: 0.5620 - val_accuracy: 0.7154\n",
            "Epoch 298/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.5489 - accuracy: 0.7251 - val_loss: 0.5617 - val_accuracy: 0.7236\n",
            "Epoch 299/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5486 - accuracy: 0.7230 - val_loss: 0.5613 - val_accuracy: 0.7236\n",
            "Epoch 300/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5481 - accuracy: 0.7271 - val_loss: 0.5609 - val_accuracy: 0.7236\n",
            "Epoch 301/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.5474 - accuracy: 0.7271 - val_loss: 0.5605 - val_accuracy: 0.7236\n",
            "Epoch 302/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5471 - accuracy: 0.7251 - val_loss: 0.5600 - val_accuracy: 0.7236\n",
            "Epoch 303/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5465 - accuracy: 0.7271 - val_loss: 0.5597 - val_accuracy: 0.7236\n",
            "Epoch 304/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5463 - accuracy: 0.7210 - val_loss: 0.5594 - val_accuracy: 0.7236\n",
            "Epoch 305/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5455 - accuracy: 0.7271 - val_loss: 0.5589 - val_accuracy: 0.7236\n",
            "Epoch 306/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5451 - accuracy: 0.7271 - val_loss: 0.5585 - val_accuracy: 0.7236\n",
            "Epoch 307/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5444 - accuracy: 0.7271 - val_loss: 0.5581 - val_accuracy: 0.7154\n",
            "Epoch 308/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5440 - accuracy: 0.7271 - val_loss: 0.5577 - val_accuracy: 0.7236\n",
            "Epoch 309/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5437 - accuracy: 0.7251 - val_loss: 0.5574 - val_accuracy: 0.7236\n",
            "Epoch 310/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5429 - accuracy: 0.7271 - val_loss: 0.5571 - val_accuracy: 0.7317\n",
            "Epoch 311/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5424 - accuracy: 0.7210 - val_loss: 0.5567 - val_accuracy: 0.7317\n",
            "Epoch 312/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5421 - accuracy: 0.7251 - val_loss: 0.5564 - val_accuracy: 0.7317\n",
            "Epoch 313/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5414 - accuracy: 0.7230 - val_loss: 0.5561 - val_accuracy: 0.7236\n",
            "Epoch 314/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5411 - accuracy: 0.7210 - val_loss: 0.5557 - val_accuracy: 0.7236\n",
            "Epoch 315/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5409 - accuracy: 0.7210 - val_loss: 0.5553 - val_accuracy: 0.7317\n",
            "Epoch 316/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5401 - accuracy: 0.7189 - val_loss: 0.5548 - val_accuracy: 0.7317\n",
            "Epoch 317/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5395 - accuracy: 0.7210 - val_loss: 0.5545 - val_accuracy: 0.7236\n",
            "Epoch 318/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5391 - accuracy: 0.7210 - val_loss: 0.5542 - val_accuracy: 0.7236\n",
            "Epoch 319/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5388 - accuracy: 0.7210 - val_loss: 0.5540 - val_accuracy: 0.7154\n",
            "Epoch 320/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5381 - accuracy: 0.7189 - val_loss: 0.5537 - val_accuracy: 0.7154\n",
            "Epoch 321/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5377 - accuracy: 0.7169 - val_loss: 0.5532 - val_accuracy: 0.7154\n",
            "Epoch 322/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5376 - accuracy: 0.7210 - val_loss: 0.5529 - val_accuracy: 0.7154\n",
            "Epoch 323/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5370 - accuracy: 0.7210 - val_loss: 0.5525 - val_accuracy: 0.7154\n",
            "Epoch 324/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5364 - accuracy: 0.7210 - val_loss: 0.5521 - val_accuracy: 0.7154\n",
            "Epoch 325/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5363 - accuracy: 0.7189 - val_loss: 0.5518 - val_accuracy: 0.7154\n",
            "Epoch 326/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5356 - accuracy: 0.7169 - val_loss: 0.5515 - val_accuracy: 0.7154\n",
            "Epoch 327/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5348 - accuracy: 0.7189 - val_loss: 0.5512 - val_accuracy: 0.7154\n",
            "Epoch 328/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5348 - accuracy: 0.7189 - val_loss: 0.5509 - val_accuracy: 0.7154\n",
            "Epoch 329/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5341 - accuracy: 0.7210 - val_loss: 0.5505 - val_accuracy: 0.7154\n",
            "Epoch 330/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5339 - accuracy: 0.7169 - val_loss: 0.5501 - val_accuracy: 0.7154\n",
            "Epoch 331/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.5331 - accuracy: 0.7210 - val_loss: 0.5499 - val_accuracy: 0.7073\n",
            "Epoch 332/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.5331 - accuracy: 0.7169 - val_loss: 0.5495 - val_accuracy: 0.7154\n",
            "Epoch 333/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5327 - accuracy: 0.7189 - val_loss: 0.5492 - val_accuracy: 0.7073\n",
            "Epoch 334/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5317 - accuracy: 0.7189 - val_loss: 0.5490 - val_accuracy: 0.7073\n",
            "Epoch 335/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5314 - accuracy: 0.7230 - val_loss: 0.5487 - val_accuracy: 0.7073\n",
            "Epoch 336/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5312 - accuracy: 0.7210 - val_loss: 0.5482 - val_accuracy: 0.7154\n",
            "Epoch 337/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5306 - accuracy: 0.7210 - val_loss: 0.5479 - val_accuracy: 0.7154\n",
            "Epoch 338/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5301 - accuracy: 0.7251 - val_loss: 0.5476 - val_accuracy: 0.7154\n",
            "Epoch 339/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5295 - accuracy: 0.7251 - val_loss: 0.5473 - val_accuracy: 0.7154\n",
            "Epoch 340/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5293 - accuracy: 0.7189 - val_loss: 0.5469 - val_accuracy: 0.7154\n",
            "Epoch 341/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5288 - accuracy: 0.7210 - val_loss: 0.5467 - val_accuracy: 0.7154\n",
            "Epoch 342/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5285 - accuracy: 0.7230 - val_loss: 0.5464 - val_accuracy: 0.7154\n",
            "Epoch 343/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5279 - accuracy: 0.7230 - val_loss: 0.5461 - val_accuracy: 0.7154\n",
            "Epoch 344/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5277 - accuracy: 0.7251 - val_loss: 0.5459 - val_accuracy: 0.7073\n",
            "Epoch 345/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5273 - accuracy: 0.7251 - val_loss: 0.5456 - val_accuracy: 0.7073\n",
            "Epoch 346/1000\n",
            "491/491 [==============================] - 0s 54us/step - loss: 0.5268 - accuracy: 0.7251 - val_loss: 0.5454 - val_accuracy: 0.6992\n",
            "Epoch 347/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5265 - accuracy: 0.7271 - val_loss: 0.5452 - val_accuracy: 0.6992\n",
            "Epoch 348/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5260 - accuracy: 0.7251 - val_loss: 0.5448 - val_accuracy: 0.6992\n",
            "Epoch 349/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5254 - accuracy: 0.7271 - val_loss: 0.5445 - val_accuracy: 0.6992\n",
            "Epoch 350/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5251 - accuracy: 0.7251 - val_loss: 0.5443 - val_accuracy: 0.6992\n",
            "Epoch 351/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5248 - accuracy: 0.7230 - val_loss: 0.5441 - val_accuracy: 0.6992\n",
            "Epoch 352/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5245 - accuracy: 0.7291 - val_loss: 0.5437 - val_accuracy: 0.6992\n",
            "Epoch 353/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5241 - accuracy: 0.7271 - val_loss: 0.5435 - val_accuracy: 0.6992\n",
            "Epoch 354/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5236 - accuracy: 0.7271 - val_loss: 0.5433 - val_accuracy: 0.6992\n",
            "Epoch 355/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5232 - accuracy: 0.7271 - val_loss: 0.5431 - val_accuracy: 0.6992\n",
            "Epoch 356/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5228 - accuracy: 0.7352 - val_loss: 0.5427 - val_accuracy: 0.6992\n",
            "Epoch 357/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5224 - accuracy: 0.7373 - val_loss: 0.5424 - val_accuracy: 0.6992\n",
            "Epoch 358/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5222 - accuracy: 0.7251 - val_loss: 0.5421 - val_accuracy: 0.6992\n",
            "Epoch 359/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5217 - accuracy: 0.7291 - val_loss: 0.5418 - val_accuracy: 0.6992\n",
            "Epoch 360/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5212 - accuracy: 0.7271 - val_loss: 0.5416 - val_accuracy: 0.6992\n",
            "Epoch 361/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5208 - accuracy: 0.7271 - val_loss: 0.5413 - val_accuracy: 0.6992\n",
            "Epoch 362/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5206 - accuracy: 0.7332 - val_loss: 0.5411 - val_accuracy: 0.6992\n",
            "Epoch 363/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5201 - accuracy: 0.7312 - val_loss: 0.5408 - val_accuracy: 0.6992\n",
            "Epoch 364/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.5195 - accuracy: 0.7312 - val_loss: 0.5407 - val_accuracy: 0.6992\n",
            "Epoch 365/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5194 - accuracy: 0.7332 - val_loss: 0.5404 - val_accuracy: 0.6992\n",
            "Epoch 366/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5191 - accuracy: 0.7332 - val_loss: 0.5401 - val_accuracy: 0.6992\n",
            "Epoch 367/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.5186 - accuracy: 0.7332 - val_loss: 0.5399 - val_accuracy: 0.6992\n",
            "Epoch 368/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.5184 - accuracy: 0.7352 - val_loss: 0.5396 - val_accuracy: 0.7073\n",
            "Epoch 369/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5179 - accuracy: 0.7312 - val_loss: 0.5394 - val_accuracy: 0.6992\n",
            "Epoch 370/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5175 - accuracy: 0.7332 - val_loss: 0.5391 - val_accuracy: 0.6992\n",
            "Epoch 371/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5171 - accuracy: 0.7332 - val_loss: 0.5390 - val_accuracy: 0.6992\n",
            "Epoch 372/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5175 - accuracy: 0.7413 - val_loss: 0.5387 - val_accuracy: 0.6992\n",
            "Epoch 373/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5165 - accuracy: 0.7373 - val_loss: 0.5384 - val_accuracy: 0.7073\n",
            "Epoch 374/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5161 - accuracy: 0.7332 - val_loss: 0.5383 - val_accuracy: 0.6992\n",
            "Epoch 375/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5156 - accuracy: 0.7373 - val_loss: 0.5381 - val_accuracy: 0.6992\n",
            "Epoch 376/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5155 - accuracy: 0.7352 - val_loss: 0.5379 - val_accuracy: 0.6992\n",
            "Epoch 377/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5151 - accuracy: 0.7373 - val_loss: 0.5376 - val_accuracy: 0.6992\n",
            "Epoch 378/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5148 - accuracy: 0.7373 - val_loss: 0.5376 - val_accuracy: 0.6992\n",
            "Epoch 379/1000\n",
            "491/491 [==============================] - 0s 63us/step - loss: 0.5147 - accuracy: 0.7413 - val_loss: 0.5373 - val_accuracy: 0.6992\n",
            "Epoch 380/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5144 - accuracy: 0.7373 - val_loss: 0.5373 - val_accuracy: 0.6992\n",
            "Epoch 381/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.5140 - accuracy: 0.7373 - val_loss: 0.5372 - val_accuracy: 0.7154\n",
            "Epoch 382/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5135 - accuracy: 0.7393 - val_loss: 0.5370 - val_accuracy: 0.7154\n",
            "Epoch 383/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5133 - accuracy: 0.7434 - val_loss: 0.5366 - val_accuracy: 0.7073\n",
            "Epoch 384/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5128 - accuracy: 0.7373 - val_loss: 0.5365 - val_accuracy: 0.7154\n",
            "Epoch 385/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5122 - accuracy: 0.7393 - val_loss: 0.5361 - val_accuracy: 0.6992\n",
            "Epoch 386/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5122 - accuracy: 0.7393 - val_loss: 0.5359 - val_accuracy: 0.6992\n",
            "Epoch 387/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5118 - accuracy: 0.7434 - val_loss: 0.5359 - val_accuracy: 0.7154\n",
            "Epoch 388/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5115 - accuracy: 0.7393 - val_loss: 0.5355 - val_accuracy: 0.7073\n",
            "Epoch 389/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5111 - accuracy: 0.7373 - val_loss: 0.5351 - val_accuracy: 0.6992\n",
            "Epoch 390/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.5109 - accuracy: 0.7352 - val_loss: 0.5350 - val_accuracy: 0.6992\n",
            "Epoch 391/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.5102 - accuracy: 0.7454 - val_loss: 0.5349 - val_accuracy: 0.7073\n",
            "Epoch 392/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5099 - accuracy: 0.7413 - val_loss: 0.5346 - val_accuracy: 0.6992\n",
            "Epoch 393/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5098 - accuracy: 0.7434 - val_loss: 0.5346 - val_accuracy: 0.7073\n",
            "Epoch 394/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5094 - accuracy: 0.7393 - val_loss: 0.5346 - val_accuracy: 0.7154\n",
            "Epoch 395/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5093 - accuracy: 0.7434 - val_loss: 0.5343 - val_accuracy: 0.7154\n",
            "Epoch 396/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5088 - accuracy: 0.7393 - val_loss: 0.5341 - val_accuracy: 0.7154\n",
            "Epoch 397/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5090 - accuracy: 0.7393 - val_loss: 0.5339 - val_accuracy: 0.7154\n",
            "Epoch 398/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5084 - accuracy: 0.7373 - val_loss: 0.5336 - val_accuracy: 0.7073\n",
            "Epoch 399/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5080 - accuracy: 0.7373 - val_loss: 0.5335 - val_accuracy: 0.7154\n",
            "Epoch 400/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5077 - accuracy: 0.7434 - val_loss: 0.5333 - val_accuracy: 0.7073\n",
            "Epoch 401/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5073 - accuracy: 0.7434 - val_loss: 0.5333 - val_accuracy: 0.7154\n",
            "Epoch 402/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5073 - accuracy: 0.7454 - val_loss: 0.5333 - val_accuracy: 0.7073\n",
            "Epoch 403/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5069 - accuracy: 0.7393 - val_loss: 0.5328 - val_accuracy: 0.7154\n",
            "Epoch 404/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5069 - accuracy: 0.7393 - val_loss: 0.5326 - val_accuracy: 0.7154\n",
            "Epoch 405/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5070 - accuracy: 0.7373 - val_loss: 0.5331 - val_accuracy: 0.7154\n",
            "Epoch 406/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.5059 - accuracy: 0.7373 - val_loss: 0.5326 - val_accuracy: 0.7154\n",
            "Epoch 407/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5058 - accuracy: 0.7332 - val_loss: 0.5325 - val_accuracy: 0.7154\n",
            "Epoch 408/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.5056 - accuracy: 0.7413 - val_loss: 0.5323 - val_accuracy: 0.7154\n",
            "Epoch 409/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.5048 - accuracy: 0.7393 - val_loss: 0.5321 - val_accuracy: 0.7154\n",
            "Epoch 410/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5053 - accuracy: 0.7413 - val_loss: 0.5322 - val_accuracy: 0.7154\n",
            "Epoch 411/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5045 - accuracy: 0.7373 - val_loss: 0.5320 - val_accuracy: 0.7154\n",
            "Epoch 412/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5040 - accuracy: 0.7393 - val_loss: 0.5318 - val_accuracy: 0.7154\n",
            "Epoch 413/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5039 - accuracy: 0.7434 - val_loss: 0.5318 - val_accuracy: 0.7154\n",
            "Epoch 414/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5035 - accuracy: 0.7454 - val_loss: 0.5317 - val_accuracy: 0.7154\n",
            "Epoch 415/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5034 - accuracy: 0.7454 - val_loss: 0.5313 - val_accuracy: 0.7154\n",
            "Epoch 416/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5032 - accuracy: 0.7454 - val_loss: 0.5312 - val_accuracy: 0.7154\n",
            "Epoch 417/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5026 - accuracy: 0.7413 - val_loss: 0.5311 - val_accuracy: 0.7154\n",
            "Epoch 418/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5026 - accuracy: 0.7393 - val_loss: 0.5311 - val_accuracy: 0.7154\n",
            "Epoch 419/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5023 - accuracy: 0.7373 - val_loss: 0.5310 - val_accuracy: 0.7154\n",
            "Epoch 420/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5022 - accuracy: 0.7434 - val_loss: 0.5313 - val_accuracy: 0.7154\n",
            "Epoch 421/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.5018 - accuracy: 0.7454 - val_loss: 0.5308 - val_accuracy: 0.7154\n",
            "Epoch 422/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5013 - accuracy: 0.7413 - val_loss: 0.5304 - val_accuracy: 0.7154\n",
            "Epoch 423/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.5008 - accuracy: 0.7454 - val_loss: 0.5303 - val_accuracy: 0.7154\n",
            "Epoch 424/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.5009 - accuracy: 0.7373 - val_loss: 0.5301 - val_accuracy: 0.7154\n",
            "Epoch 425/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.5004 - accuracy: 0.7454 - val_loss: 0.5302 - val_accuracy: 0.7154\n",
            "Epoch 426/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5003 - accuracy: 0.7434 - val_loss: 0.5301 - val_accuracy: 0.7154\n",
            "Epoch 427/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5006 - accuracy: 0.7413 - val_loss: 0.5297 - val_accuracy: 0.7154\n",
            "Epoch 428/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.5000 - accuracy: 0.7475 - val_loss: 0.5296 - val_accuracy: 0.7154\n",
            "Epoch 429/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.5001 - accuracy: 0.7454 - val_loss: 0.5299 - val_accuracy: 0.7154\n",
            "Epoch 430/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4992 - accuracy: 0.7413 - val_loss: 0.5297 - val_accuracy: 0.7154\n",
            "Epoch 431/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4988 - accuracy: 0.7434 - val_loss: 0.5293 - val_accuracy: 0.7154\n",
            "Epoch 432/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4988 - accuracy: 0.7393 - val_loss: 0.5290 - val_accuracy: 0.7236\n",
            "Epoch 433/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4987 - accuracy: 0.7454 - val_loss: 0.5291 - val_accuracy: 0.7154\n",
            "Epoch 434/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4984 - accuracy: 0.7475 - val_loss: 0.5293 - val_accuracy: 0.7154\n",
            "Epoch 435/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4981 - accuracy: 0.7454 - val_loss: 0.5289 - val_accuracy: 0.7154\n",
            "Epoch 436/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4977 - accuracy: 0.7515 - val_loss: 0.5290 - val_accuracy: 0.7154\n",
            "Epoch 437/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4977 - accuracy: 0.7434 - val_loss: 0.5287 - val_accuracy: 0.7154\n",
            "Epoch 438/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4974 - accuracy: 0.7434 - val_loss: 0.5285 - val_accuracy: 0.7236\n",
            "Epoch 439/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4972 - accuracy: 0.7454 - val_loss: 0.5285 - val_accuracy: 0.7154\n",
            "Epoch 440/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4968 - accuracy: 0.7495 - val_loss: 0.5283 - val_accuracy: 0.7236\n",
            "Epoch 441/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4970 - accuracy: 0.7454 - val_loss: 0.5282 - val_accuracy: 0.7236\n",
            "Epoch 442/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4967 - accuracy: 0.7515 - val_loss: 0.5281 - val_accuracy: 0.7236\n",
            "Epoch 443/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4962 - accuracy: 0.7515 - val_loss: 0.5282 - val_accuracy: 0.7154\n",
            "Epoch 444/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4961 - accuracy: 0.7515 - val_loss: 0.5281 - val_accuracy: 0.7154\n",
            "Epoch 445/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4956 - accuracy: 0.7515 - val_loss: 0.5280 - val_accuracy: 0.7236\n",
            "Epoch 446/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4953 - accuracy: 0.7495 - val_loss: 0.5278 - val_accuracy: 0.7236\n",
            "Epoch 447/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4952 - accuracy: 0.7454 - val_loss: 0.5276 - val_accuracy: 0.7236\n",
            "Epoch 448/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4948 - accuracy: 0.7515 - val_loss: 0.5276 - val_accuracy: 0.7236\n",
            "Epoch 449/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4947 - accuracy: 0.7495 - val_loss: 0.5277 - val_accuracy: 0.7236\n",
            "Epoch 450/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4945 - accuracy: 0.7495 - val_loss: 0.5279 - val_accuracy: 0.7154\n",
            "Epoch 451/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4944 - accuracy: 0.7495 - val_loss: 0.5277 - val_accuracy: 0.7154\n",
            "Epoch 452/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4942 - accuracy: 0.7515 - val_loss: 0.5274 - val_accuracy: 0.7236\n",
            "Epoch 453/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4940 - accuracy: 0.7454 - val_loss: 0.5273 - val_accuracy: 0.7236\n",
            "Epoch 454/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4937 - accuracy: 0.7475 - val_loss: 0.5274 - val_accuracy: 0.7236\n",
            "Epoch 455/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4934 - accuracy: 0.7475 - val_loss: 0.5275 - val_accuracy: 0.7154\n",
            "Epoch 456/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4934 - accuracy: 0.7475 - val_loss: 0.5278 - val_accuracy: 0.7236\n",
            "Epoch 457/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4928 - accuracy: 0.7495 - val_loss: 0.5272 - val_accuracy: 0.7236\n",
            "Epoch 458/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4928 - accuracy: 0.7495 - val_loss: 0.5275 - val_accuracy: 0.7154\n",
            "Epoch 459/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4924 - accuracy: 0.7454 - val_loss: 0.5269 - val_accuracy: 0.7236\n",
            "Epoch 460/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4921 - accuracy: 0.7495 - val_loss: 0.5270 - val_accuracy: 0.7236\n",
            "Epoch 461/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4923 - accuracy: 0.7475 - val_loss: 0.5272 - val_accuracy: 0.7154\n",
            "Epoch 462/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4920 - accuracy: 0.7475 - val_loss: 0.5268 - val_accuracy: 0.7236\n",
            "Epoch 463/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4914 - accuracy: 0.7495 - val_loss: 0.5269 - val_accuracy: 0.7236\n",
            "Epoch 464/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4915 - accuracy: 0.7495 - val_loss: 0.5265 - val_accuracy: 0.7236\n",
            "Epoch 465/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4922 - accuracy: 0.7475 - val_loss: 0.5264 - val_accuracy: 0.7236\n",
            "Epoch 466/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4910 - accuracy: 0.7475 - val_loss: 0.5263 - val_accuracy: 0.7317\n",
            "Epoch 467/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4913 - accuracy: 0.7515 - val_loss: 0.5264 - val_accuracy: 0.7236\n",
            "Epoch 468/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4906 - accuracy: 0.7475 - val_loss: 0.5263 - val_accuracy: 0.7236\n",
            "Epoch 469/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4915 - accuracy: 0.7434 - val_loss: 0.5262 - val_accuracy: 0.7317\n",
            "Epoch 470/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4903 - accuracy: 0.7515 - val_loss: 0.5261 - val_accuracy: 0.7317\n",
            "Epoch 471/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4902 - accuracy: 0.7475 - val_loss: 0.5261 - val_accuracy: 0.7317\n",
            "Epoch 472/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4899 - accuracy: 0.7515 - val_loss: 0.5260 - val_accuracy: 0.7317\n",
            "Epoch 473/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4899 - accuracy: 0.7495 - val_loss: 0.5258 - val_accuracy: 0.7317\n",
            "Epoch 474/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4899 - accuracy: 0.7515 - val_loss: 0.5258 - val_accuracy: 0.7317\n",
            "Epoch 475/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4890 - accuracy: 0.7515 - val_loss: 0.5261 - val_accuracy: 0.7236\n",
            "Epoch 476/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4890 - accuracy: 0.7495 - val_loss: 0.5260 - val_accuracy: 0.7236\n",
            "Epoch 477/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4890 - accuracy: 0.7515 - val_loss: 0.5257 - val_accuracy: 0.7317\n",
            "Epoch 478/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4892 - accuracy: 0.7495 - val_loss: 0.5257 - val_accuracy: 0.7317\n",
            "Epoch 479/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4883 - accuracy: 0.7495 - val_loss: 0.5261 - val_accuracy: 0.7317\n",
            "Epoch 480/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4885 - accuracy: 0.7536 - val_loss: 0.5257 - val_accuracy: 0.7317\n",
            "Epoch 481/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4881 - accuracy: 0.7515 - val_loss: 0.5254 - val_accuracy: 0.7317\n",
            "Epoch 482/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4889 - accuracy: 0.7515 - val_loss: 0.5256 - val_accuracy: 0.7317\n",
            "Epoch 483/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4879 - accuracy: 0.7515 - val_loss: 0.5254 - val_accuracy: 0.7317\n",
            "Epoch 484/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4881 - accuracy: 0.7515 - val_loss: 0.5257 - val_accuracy: 0.7398\n",
            "Epoch 485/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4872 - accuracy: 0.7515 - val_loss: 0.5259 - val_accuracy: 0.7317\n",
            "Epoch 486/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4872 - accuracy: 0.7515 - val_loss: 0.5257 - val_accuracy: 0.7398\n",
            "Epoch 487/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4868 - accuracy: 0.7536 - val_loss: 0.5258 - val_accuracy: 0.7398\n",
            "Epoch 488/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4870 - accuracy: 0.7576 - val_loss: 0.5251 - val_accuracy: 0.7317\n",
            "Epoch 489/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4868 - accuracy: 0.7515 - val_loss: 0.5253 - val_accuracy: 0.7317\n",
            "Epoch 490/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4863 - accuracy: 0.7495 - val_loss: 0.5253 - val_accuracy: 0.7317\n",
            "Epoch 491/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4862 - accuracy: 0.7556 - val_loss: 0.5251 - val_accuracy: 0.7317\n",
            "Epoch 492/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4861 - accuracy: 0.7495 - val_loss: 0.5252 - val_accuracy: 0.7317\n",
            "Epoch 493/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4857 - accuracy: 0.7556 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
            "Epoch 494/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4858 - accuracy: 0.7515 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
            "Epoch 495/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4855 - accuracy: 0.7515 - val_loss: 0.5253 - val_accuracy: 0.7398\n",
            "Epoch 496/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4856 - accuracy: 0.7556 - val_loss: 0.5255 - val_accuracy: 0.7398\n",
            "Epoch 497/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4852 - accuracy: 0.7556 - val_loss: 0.5249 - val_accuracy: 0.7317\n",
            "Epoch 498/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4857 - accuracy: 0.7515 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
            "Epoch 499/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4852 - accuracy: 0.7556 - val_loss: 0.5250 - val_accuracy: 0.7317\n",
            "Epoch 500/1000\n",
            "491/491 [==============================] - 0s 59us/step - loss: 0.4846 - accuracy: 0.7536 - val_loss: 0.5251 - val_accuracy: 0.7398\n",
            "Epoch 501/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4848 - accuracy: 0.7576 - val_loss: 0.5253 - val_accuracy: 0.7398\n",
            "Epoch 502/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4849 - accuracy: 0.7597 - val_loss: 0.5253 - val_accuracy: 0.7398\n",
            "Epoch 503/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4848 - accuracy: 0.7515 - val_loss: 0.5249 - val_accuracy: 0.7317\n",
            "Epoch 504/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4841 - accuracy: 0.7556 - val_loss: 0.5251 - val_accuracy: 0.7398\n",
            "Epoch 505/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4843 - accuracy: 0.7576 - val_loss: 0.5253 - val_accuracy: 0.7398\n",
            "Epoch 506/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4835 - accuracy: 0.7556 - val_loss: 0.5248 - val_accuracy: 0.7398\n",
            "Epoch 507/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4834 - accuracy: 0.7536 - val_loss: 0.5247 - val_accuracy: 0.7317\n",
            "Epoch 508/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4844 - accuracy: 0.7556 - val_loss: 0.5247 - val_accuracy: 0.7398\n",
            "Epoch 509/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4837 - accuracy: 0.7556 - val_loss: 0.5246 - val_accuracy: 0.7317\n",
            "Epoch 510/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4837 - accuracy: 0.7536 - val_loss: 0.5246 - val_accuracy: 0.7317\n",
            "Epoch 511/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4828 - accuracy: 0.7556 - val_loss: 0.5245 - val_accuracy: 0.7398\n",
            "Epoch 512/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4833 - accuracy: 0.7536 - val_loss: 0.5246 - val_accuracy: 0.7317\n",
            "Epoch 513/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4826 - accuracy: 0.7576 - val_loss: 0.5246 - val_accuracy: 0.7317\n",
            "Epoch 514/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4835 - accuracy: 0.7495 - val_loss: 0.5247 - val_accuracy: 0.7480\n",
            "Epoch 515/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4824 - accuracy: 0.7597 - val_loss: 0.5248 - val_accuracy: 0.7398\n",
            "Epoch 516/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4825 - accuracy: 0.7617 - val_loss: 0.5249 - val_accuracy: 0.7398\n",
            "Epoch 517/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4826 - accuracy: 0.7556 - val_loss: 0.5249 - val_accuracy: 0.7398\n",
            "Epoch 518/1000\n",
            "491/491 [==============================] - 0s 53us/step - loss: 0.4821 - accuracy: 0.7556 - val_loss: 0.5249 - val_accuracy: 0.7398\n",
            "Epoch 519/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4824 - accuracy: 0.7556 - val_loss: 0.5244 - val_accuracy: 0.7398\n",
            "Epoch 520/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4820 - accuracy: 0.7515 - val_loss: 0.5246 - val_accuracy: 0.7480\n",
            "Epoch 521/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4816 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 522/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4816 - accuracy: 0.7597 - val_loss: 0.5248 - val_accuracy: 0.7398\n",
            "Epoch 523/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4812 - accuracy: 0.7617 - val_loss: 0.5244 - val_accuracy: 0.7398\n",
            "Epoch 524/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4811 - accuracy: 0.7556 - val_loss: 0.5243 - val_accuracy: 0.7480\n",
            "Epoch 525/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4813 - accuracy: 0.7495 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 526/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4812 - accuracy: 0.7576 - val_loss: 0.5244 - val_accuracy: 0.7480\n",
            "Epoch 527/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4808 - accuracy: 0.7536 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 528/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4809 - accuracy: 0.7597 - val_loss: 0.5248 - val_accuracy: 0.7398\n",
            "Epoch 529/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4810 - accuracy: 0.7576 - val_loss: 0.5243 - val_accuracy: 0.7561\n",
            "Epoch 530/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4805 - accuracy: 0.7556 - val_loss: 0.5244 - val_accuracy: 0.7480\n",
            "Epoch 531/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4800 - accuracy: 0.7637 - val_loss: 0.5243 - val_accuracy: 0.7480\n",
            "Epoch 532/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4804 - accuracy: 0.7597 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 533/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4797 - accuracy: 0.7576 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 534/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4802 - accuracy: 0.7637 - val_loss: 0.5242 - val_accuracy: 0.7480\n",
            "Epoch 535/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4797 - accuracy: 0.7576 - val_loss: 0.5242 - val_accuracy: 0.7480\n",
            "Epoch 536/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4797 - accuracy: 0.7576 - val_loss: 0.5243 - val_accuracy: 0.7561\n",
            "Epoch 537/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4795 - accuracy: 0.7576 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 538/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4794 - accuracy: 0.7637 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 539/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4792 - accuracy: 0.7597 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 540/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4792 - accuracy: 0.7597 - val_loss: 0.5243 - val_accuracy: 0.7561\n",
            "Epoch 541/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4796 - accuracy: 0.7597 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 542/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4790 - accuracy: 0.7597 - val_loss: 0.5246 - val_accuracy: 0.7480\n",
            "Epoch 543/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4785 - accuracy: 0.7617 - val_loss: 0.5246 - val_accuracy: 0.7480\n",
            "Epoch 544/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4788 - accuracy: 0.7658 - val_loss: 0.5243 - val_accuracy: 0.7561\n",
            "Epoch 545/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4784 - accuracy: 0.7658 - val_loss: 0.5242 - val_accuracy: 0.7480\n",
            "Epoch 546/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4785 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 547/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4781 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7480\n",
            "Epoch 548/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4781 - accuracy: 0.7617 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 549/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4777 - accuracy: 0.7637 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 550/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4779 - accuracy: 0.7617 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 551/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4777 - accuracy: 0.7658 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 552/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4780 - accuracy: 0.7597 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 553/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4772 - accuracy: 0.7699 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 554/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4779 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 555/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4774 - accuracy: 0.7617 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 556/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4773 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 557/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4780 - accuracy: 0.7637 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 558/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4771 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7480\n",
            "Epoch 559/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4771 - accuracy: 0.7658 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 560/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4770 - accuracy: 0.7658 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 561/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4768 - accuracy: 0.7719 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 562/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4766 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 563/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4764 - accuracy: 0.7678 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 564/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4762 - accuracy: 0.7658 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 565/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4763 - accuracy: 0.7719 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 566/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 567/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4762 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 568/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4758 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7561\n",
            "Epoch 569/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4757 - accuracy: 0.7678 - val_loss: 0.5244 - val_accuracy: 0.7642\n",
            "Epoch 570/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4773 - accuracy: 0.7699 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 571/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4775 - accuracy: 0.7658 - val_loss: 0.5245 - val_accuracy: 0.7642\n",
            "Epoch 572/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4754 - accuracy: 0.7719 - val_loss: 0.5245 - val_accuracy: 0.7642\n",
            "Epoch 573/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4759 - accuracy: 0.7699 - val_loss: 0.5245 - val_accuracy: 0.7642\n",
            "Epoch 574/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4764 - accuracy: 0.7678 - val_loss: 0.5245 - val_accuracy: 0.7561\n",
            "Epoch 575/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4756 - accuracy: 0.7678 - val_loss: 0.5245 - val_accuracy: 0.7642\n",
            "Epoch 576/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4753 - accuracy: 0.7719 - val_loss: 0.5245 - val_accuracy: 0.7398\n",
            "Epoch 577/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4749 - accuracy: 0.7719 - val_loss: 0.5245 - val_accuracy: 0.7724\n",
            "Epoch 578/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4747 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7724\n",
            "Epoch 579/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4747 - accuracy: 0.7739 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 580/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4746 - accuracy: 0.7678 - val_loss: 0.5248 - val_accuracy: 0.7642\n",
            "Epoch 581/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4751 - accuracy: 0.7699 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 582/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4752 - accuracy: 0.7699 - val_loss: 0.5246 - val_accuracy: 0.7724\n",
            "Epoch 583/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4750 - accuracy: 0.7678 - val_loss: 0.5245 - val_accuracy: 0.7398\n",
            "Epoch 584/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4744 - accuracy: 0.7739 - val_loss: 0.5246 - val_accuracy: 0.7642\n",
            "Epoch 585/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4742 - accuracy: 0.7699 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 586/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4742 - accuracy: 0.7719 - val_loss: 0.5248 - val_accuracy: 0.7642\n",
            "Epoch 587/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4739 - accuracy: 0.7678 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
            "Epoch 588/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4740 - accuracy: 0.7719 - val_loss: 0.5246 - val_accuracy: 0.7642\n",
            "Epoch 589/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4745 - accuracy: 0.7719 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 590/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4739 - accuracy: 0.7699 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 591/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4745 - accuracy: 0.7699 - val_loss: 0.5250 - val_accuracy: 0.7642\n",
            "Epoch 592/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4738 - accuracy: 0.7678 - val_loss: 0.5246 - val_accuracy: 0.7642\n",
            "Epoch 593/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4733 - accuracy: 0.7719 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 594/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4737 - accuracy: 0.7699 - val_loss: 0.5246 - val_accuracy: 0.7642\n",
            "Epoch 595/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4737 - accuracy: 0.7739 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 596/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4734 - accuracy: 0.7719 - val_loss: 0.5246 - val_accuracy: 0.7642\n",
            "Epoch 597/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4739 - accuracy: 0.7719 - val_loss: 0.5248 - val_accuracy: 0.7642\n",
            "Epoch 598/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4731 - accuracy: 0.7678 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 599/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4733 - accuracy: 0.7739 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 600/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4733 - accuracy: 0.7699 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 601/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.5247 - val_accuracy: 0.7480\n",
            "Epoch 602/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4733 - accuracy: 0.7719 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
            "Epoch 603/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4726 - accuracy: 0.7719 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
            "Epoch 604/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4728 - accuracy: 0.7739 - val_loss: 0.5247 - val_accuracy: 0.7480\n",
            "Epoch 605/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4734 - accuracy: 0.7800 - val_loss: 0.5248 - val_accuracy: 0.7480\n",
            "Epoch 606/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4730 - accuracy: 0.7699 - val_loss: 0.5248 - val_accuracy: 0.7642\n",
            "Epoch 607/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4733 - accuracy: 0.7699 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 608/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4730 - accuracy: 0.7719 - val_loss: 0.5250 - val_accuracy: 0.7642\n",
            "Epoch 609/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4725 - accuracy: 0.7699 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 610/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4726 - accuracy: 0.7719 - val_loss: 0.5252 - val_accuracy: 0.7642\n",
            "Epoch 611/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4724 - accuracy: 0.7719 - val_loss: 0.5250 - val_accuracy: 0.7561\n",
            "Epoch 612/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4722 - accuracy: 0.7739 - val_loss: 0.5254 - val_accuracy: 0.7642\n",
            "Epoch 613/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4722 - accuracy: 0.7719 - val_loss: 0.5253 - val_accuracy: 0.7642\n",
            "Epoch 614/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.5253 - val_accuracy: 0.7642\n",
            "Epoch 615/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4721 - accuracy: 0.7780 - val_loss: 0.5249 - val_accuracy: 0.7642\n",
            "Epoch 616/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4718 - accuracy: 0.7719 - val_loss: 0.5250 - val_accuracy: 0.7561\n",
            "Epoch 617/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4716 - accuracy: 0.7719 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 618/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4717 - accuracy: 0.7780 - val_loss: 0.5250 - val_accuracy: 0.7642\n",
            "Epoch 619/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
            "Epoch 620/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4718 - accuracy: 0.7719 - val_loss: 0.5250 - val_accuracy: 0.7642\n",
            "Epoch 621/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4714 - accuracy: 0.7739 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 622/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4716 - accuracy: 0.7780 - val_loss: 0.5252 - val_accuracy: 0.7561\n",
            "Epoch 623/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4716 - accuracy: 0.7719 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 624/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4718 - accuracy: 0.7699 - val_loss: 0.5250 - val_accuracy: 0.7642\n",
            "Epoch 625/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4724 - accuracy: 0.7739 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 626/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 627/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4712 - accuracy: 0.7719 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 628/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7561\n",
            "Epoch 629/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 630/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4716 - accuracy: 0.7739 - val_loss: 0.5252 - val_accuracy: 0.7561\n",
            "Epoch 631/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4714 - accuracy: 0.7739 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 632/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4708 - accuracy: 0.7739 - val_loss: 0.5251 - val_accuracy: 0.7642\n",
            "Epoch 633/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 634/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.4706 - accuracy: 0.7699 - val_loss: 0.5252 - val_accuracy: 0.7642\n",
            "Epoch 635/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 636/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.5252 - val_accuracy: 0.7642\n",
            "Epoch 637/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 638/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 639/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4711 - accuracy: 0.7739 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 640/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4707 - accuracy: 0.7699 - val_loss: 0.5253 - val_accuracy: 0.7642\n",
            "Epoch 641/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4711 - accuracy: 0.7699 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 642/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4707 - accuracy: 0.7699 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 643/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4710 - accuracy: 0.7780 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 644/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4701 - accuracy: 0.7780 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 645/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4700 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 646/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 647/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.5260 - val_accuracy: 0.7724\n",
            "Epoch 648/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4703 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 649/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4698 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 650/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4701 - accuracy: 0.7719 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 651/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4699 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 652/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4705 - accuracy: 0.7699 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 653/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4703 - accuracy: 0.7760 - val_loss: 0.5254 - val_accuracy: 0.7480\n",
            "Epoch 654/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4696 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 655/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4695 - accuracy: 0.7719 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 656/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4699 - accuracy: 0.7739 - val_loss: 0.5254 - val_accuracy: 0.7642\n",
            "Epoch 657/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4697 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 658/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4695 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 659/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4696 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 660/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4707 - accuracy: 0.7699 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 661/1000\n",
            "491/491 [==============================] - 0s 56us/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 662/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4694 - accuracy: 0.7739 - val_loss: 0.5261 - val_accuracy: 0.7642\n",
            "Epoch 663/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4693 - accuracy: 0.7800 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 664/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4699 - accuracy: 0.7780 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 665/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4694 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 666/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.5254 - val_accuracy: 0.7561\n",
            "Epoch 667/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4687 - accuracy: 0.7719 - val_loss: 0.5254 - val_accuracy: 0.7642\n",
            "Epoch 668/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.5255 - val_accuracy: 0.7480\n",
            "Epoch 669/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4689 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 670/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4697 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 671/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 672/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4697 - accuracy: 0.7699 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 673/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4690 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 674/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4688 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 675/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4686 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 676/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4684 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 677/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4682 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 678/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4683 - accuracy: 0.7780 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 679/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4691 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 680/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4685 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 681/1000\n",
            "491/491 [==============================] - 0s 49us/step - loss: 0.4678 - accuracy: 0.7760 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 682/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 683/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4694 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 684/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4683 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 685/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 686/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4679 - accuracy: 0.7739 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 687/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4690 - accuracy: 0.7699 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 688/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4680 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 689/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4679 - accuracy: 0.7780 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 690/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4680 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 691/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4685 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 692/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4688 - accuracy: 0.7760 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 693/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4676 - accuracy: 0.7739 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 694/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4675 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 695/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4674 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 696/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4690 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 697/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4689 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 698/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4679 - accuracy: 0.7739 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 699/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4678 - accuracy: 0.7821 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 700/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4684 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 701/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4684 - accuracy: 0.7699 - val_loss: 0.5261 - val_accuracy: 0.7642\n",
            "Epoch 702/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4674 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 703/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4675 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 704/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 705/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4678 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 706/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4673 - accuracy: 0.7780 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 707/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4682 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 708/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4677 - accuracy: 0.7719 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 709/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4674 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 710/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4673 - accuracy: 0.7739 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 711/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4671 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 712/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4678 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 713/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 714/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4673 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 715/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4671 - accuracy: 0.7739 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 716/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4667 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 717/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4665 - accuracy: 0.7739 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 718/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4675 - accuracy: 0.7699 - val_loss: 0.5262 - val_accuracy: 0.7724\n",
            "Epoch 719/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.5264 - val_accuracy: 0.7724\n",
            "Epoch 720/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4679 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 721/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4671 - accuracy: 0.7719 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 722/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4674 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 723/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4669 - accuracy: 0.7739 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 724/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4670 - accuracy: 0.7719 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 725/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4666 - accuracy: 0.7658 - val_loss: 0.5265 - val_accuracy: 0.7642\n",
            "Epoch 726/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4667 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 727/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4668 - accuracy: 0.7658 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 728/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4672 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7480\n",
            "Epoch 729/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4670 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 730/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4666 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 731/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4665 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7480\n",
            "Epoch 732/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4664 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7724\n",
            "Epoch 733/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4683 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 734/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4675 - accuracy: 0.7699 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 735/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 736/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4661 - accuracy: 0.7739 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 737/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4664 - accuracy: 0.7699 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 738/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4663 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 739/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4664 - accuracy: 0.7678 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 740/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4662 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7642\n",
            "Epoch 741/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4662 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7480\n",
            "Epoch 742/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4664 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 743/1000\n",
            "491/491 [==============================] - 0s 47us/step - loss: 0.4664 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 744/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4659 - accuracy: 0.7739 - val_loss: 0.5262 - val_accuracy: 0.7724\n",
            "Epoch 745/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4663 - accuracy: 0.7739 - val_loss: 0.5261 - val_accuracy: 0.7724\n",
            "Epoch 746/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4657 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 747/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4665 - accuracy: 0.7719 - val_loss: 0.5260 - val_accuracy: 0.7480\n",
            "Epoch 748/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4663 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 749/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4661 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 750/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4661 - accuracy: 0.7658 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 751/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4655 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 752/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4668 - accuracy: 0.7658 - val_loss: 0.5256 - val_accuracy: 0.7642\n",
            "Epoch 753/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 754/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4654 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 755/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4675 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 756/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4652 - accuracy: 0.7699 - val_loss: 0.5259 - val_accuracy: 0.7724\n",
            "Epoch 757/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4656 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 758/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4657 - accuracy: 0.7719 - val_loss: 0.5255 - val_accuracy: 0.7561\n",
            "Epoch 759/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4659 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7642\n",
            "Epoch 760/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4670 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7724\n",
            "Epoch 761/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4666 - accuracy: 0.7637 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 762/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4656 - accuracy: 0.7739 - val_loss: 0.5256 - val_accuracy: 0.7642\n",
            "Epoch 763/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4653 - accuracy: 0.7719 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 764/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4657 - accuracy: 0.7699 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 765/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4654 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7480\n",
            "Epoch 766/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4656 - accuracy: 0.7739 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 767/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7642\n",
            "Epoch 768/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4657 - accuracy: 0.7739 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 769/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 770/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 771/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 772/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4648 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 773/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4657 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7724\n",
            "Epoch 774/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4654 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 775/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4657 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7724\n",
            "Epoch 776/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4650 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 777/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4650 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7724\n",
            "Epoch 778/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4658 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7724\n",
            "Epoch 779/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4649 - accuracy: 0.7699 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 780/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4654 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 781/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 782/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4654 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 783/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4659 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 784/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5266 - val_accuracy: 0.7642\n",
            "Epoch 785/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4655 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 786/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 787/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4648 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 788/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4652 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 789/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4652 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 790/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4653 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 791/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4644 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 792/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4650 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 793/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4655 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 794/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4646 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 795/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4646 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 796/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4656 - accuracy: 0.7637 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 797/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4648 - accuracy: 0.7800 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 798/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4648 - accuracy: 0.7637 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 799/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 800/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4645 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 801/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4646 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 802/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4642 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 803/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4650 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 804/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 805/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 806/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 807/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4645 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 808/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4642 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 809/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4663 - accuracy: 0.7699 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 810/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4648 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 811/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4643 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 812/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4647 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 813/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4642 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 814/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4643 - accuracy: 0.7637 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 815/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4643 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7642\n",
            "Epoch 816/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4644 - accuracy: 0.7678 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 817/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4649 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 818/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 819/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4646 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 820/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 821/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4641 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7642\n",
            "Epoch 822/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4647 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 823/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4638 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 824/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4646 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 825/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4642 - accuracy: 0.7678 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 826/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 827/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4637 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 828/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4641 - accuracy: 0.7719 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 829/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4641 - accuracy: 0.7637 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 830/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 831/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4641 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 832/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4634 - accuracy: 0.7658 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 833/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 834/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4639 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 835/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 836/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4639 - accuracy: 0.7637 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 837/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4643 - accuracy: 0.7637 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 838/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4638 - accuracy: 0.7699 - val_loss: 0.5257 - val_accuracy: 0.7642\n",
            "Epoch 839/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4644 - accuracy: 0.7658 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 840/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4636 - accuracy: 0.7637 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 841/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4639 - accuracy: 0.7637 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 842/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4632 - accuracy: 0.7678 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
            "Epoch 843/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4632 - accuracy: 0.7658 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 844/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4640 - accuracy: 0.7658 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 845/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4636 - accuracy: 0.7699 - val_loss: 0.5258 - val_accuracy: 0.7561\n",
            "Epoch 846/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4635 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 847/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4638 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 848/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4640 - accuracy: 0.7699 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 849/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4631 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 850/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4630 - accuracy: 0.7678 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 851/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4640 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 852/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4633 - accuracy: 0.7699 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 853/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4629 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 854/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4630 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 855/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4631 - accuracy: 0.7658 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 856/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4632 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 857/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4637 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7642\n",
            "Epoch 858/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4636 - accuracy: 0.7637 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 859/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4632 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 860/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 861/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4635 - accuracy: 0.7739 - val_loss: 0.5260 - val_accuracy: 0.7642\n",
            "Epoch 862/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4647 - accuracy: 0.7719 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 863/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4632 - accuracy: 0.7699 - val_loss: 0.5261 - val_accuracy: 0.7642\n",
            "Epoch 864/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 865/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4635 - accuracy: 0.7678 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 866/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4631 - accuracy: 0.7699 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 867/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4628 - accuracy: 0.7678 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 868/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4630 - accuracy: 0.7658 - val_loss: 0.5260 - val_accuracy: 0.7561\n",
            "Epoch 869/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4638 - accuracy: 0.7637 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 870/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4638 - accuracy: 0.7678 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 871/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4636 - accuracy: 0.7678 - val_loss: 0.5261 - val_accuracy: 0.7561\n",
            "Epoch 872/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.5262 - val_accuracy: 0.7642\n",
            "Epoch 873/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5262 - val_accuracy: 0.7480\n",
            "Epoch 874/1000\n",
            "491/491 [==============================] - 0s 45us/step - loss: 0.4631 - accuracy: 0.7678 - val_loss: 0.5263 - val_accuracy: 0.7642\n",
            "Epoch 875/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4629 - accuracy: 0.7678 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 876/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 877/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4632 - accuracy: 0.7699 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 878/1000\n",
            "491/491 [==============================] - 0s 50us/step - loss: 0.4628 - accuracy: 0.7658 - val_loss: 0.5263 - val_accuracy: 0.7480\n",
            "Epoch 879/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4628 - accuracy: 0.7658 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 880/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5266 - val_accuracy: 0.7561\n",
            "Epoch 881/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4627 - accuracy: 0.7719 - val_loss: 0.5263 - val_accuracy: 0.7561\n",
            "Epoch 882/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4633 - accuracy: 0.7658 - val_loss: 0.5263 - val_accuracy: 0.7561\n",
            "Epoch 883/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4642 - accuracy: 0.7719 - val_loss: 0.5264 - val_accuracy: 0.7480\n",
            "Epoch 884/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4636 - accuracy: 0.7699 - val_loss: 0.5264 - val_accuracy: 0.7561\n",
            "Epoch 885/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4628 - accuracy: 0.7678 - val_loss: 0.5264 - val_accuracy: 0.7480\n",
            "Epoch 886/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4632 - accuracy: 0.7699 - val_loss: 0.5264 - val_accuracy: 0.7561\n",
            "Epoch 887/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4634 - accuracy: 0.7719 - val_loss: 0.5264 - val_accuracy: 0.7561\n",
            "Epoch 888/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5265 - val_accuracy: 0.7561\n",
            "Epoch 889/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4625 - accuracy: 0.7637 - val_loss: 0.5264 - val_accuracy: 0.7561\n",
            "Epoch 890/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4626 - accuracy: 0.7678 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 891/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4626 - accuracy: 0.7760 - val_loss: 0.5266 - val_accuracy: 0.7561\n",
            "Epoch 892/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4622 - accuracy: 0.7699 - val_loss: 0.5266 - val_accuracy: 0.7561\n",
            "Epoch 893/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4631 - accuracy: 0.7658 - val_loss: 0.5265 - val_accuracy: 0.7561\n",
            "Epoch 894/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4632 - accuracy: 0.7637 - val_loss: 0.5267 - val_accuracy: 0.7480\n",
            "Epoch 895/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4628 - accuracy: 0.7699 - val_loss: 0.5269 - val_accuracy: 0.7642\n",
            "Epoch 896/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4626 - accuracy: 0.7719 - val_loss: 0.5268 - val_accuracy: 0.7642\n",
            "Epoch 897/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4625 - accuracy: 0.7658 - val_loss: 0.5267 - val_accuracy: 0.7480\n",
            "Epoch 898/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4634 - accuracy: 0.7719 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 899/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4623 - accuracy: 0.7719 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 900/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4623 - accuracy: 0.7637 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 901/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4633 - accuracy: 0.7617 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 902/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4625 - accuracy: 0.7658 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 903/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4628 - accuracy: 0.7658 - val_loss: 0.5270 - val_accuracy: 0.7642\n",
            "Epoch 904/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4626 - accuracy: 0.7678 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
            "Epoch 905/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4625 - accuracy: 0.7658 - val_loss: 0.5267 - val_accuracy: 0.7561\n",
            "Epoch 906/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4631 - accuracy: 0.7678 - val_loss: 0.5268 - val_accuracy: 0.7561\n",
            "Epoch 907/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4622 - accuracy: 0.7658 - val_loss: 0.5268 - val_accuracy: 0.7561\n",
            "Epoch 908/1000\n",
            "491/491 [==============================] - 0s 31us/step - loss: 0.4627 - accuracy: 0.7678 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
            "Epoch 909/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4623 - accuracy: 0.7678 - val_loss: 0.5271 - val_accuracy: 0.7642\n",
            "Epoch 910/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4629 - accuracy: 0.7699 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 911/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4620 - accuracy: 0.7658 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 912/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4630 - accuracy: 0.7719 - val_loss: 0.5270 - val_accuracy: 0.7642\n",
            "Epoch 913/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4633 - accuracy: 0.7678 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
            "Epoch 914/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4621 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 915/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4636 - accuracy: 0.7699 - val_loss: 0.5271 - val_accuracy: 0.7642\n",
            "Epoch 916/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4633 - accuracy: 0.7739 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
            "Epoch 917/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4620 - accuracy: 0.7678 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
            "Epoch 918/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4618 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 919/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
            "Epoch 920/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4627 - accuracy: 0.7719 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 921/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4629 - accuracy: 0.7658 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 922/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4623 - accuracy: 0.7699 - val_loss: 0.5269 - val_accuracy: 0.7480\n",
            "Epoch 923/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4620 - accuracy: 0.7719 - val_loss: 0.5270 - val_accuracy: 0.7561\n",
            "Epoch 924/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4621 - accuracy: 0.7678 - val_loss: 0.5271 - val_accuracy: 0.7561\n",
            "Epoch 925/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4619 - accuracy: 0.7658 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
            "Epoch 926/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4624 - accuracy: 0.7678 - val_loss: 0.5270 - val_accuracy: 0.7480\n",
            "Epoch 927/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4622 - accuracy: 0.7678 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 928/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 929/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7658 - val_loss: 0.5269 - val_accuracy: 0.7561\n",
            "Epoch 930/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4620 - accuracy: 0.7658 - val_loss: 0.5270 - val_accuracy: 0.7561\n",
            "Epoch 931/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4626 - accuracy: 0.7699 - val_loss: 0.5270 - val_accuracy: 0.7561\n",
            "Epoch 932/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4620 - accuracy: 0.7658 - val_loss: 0.5271 - val_accuracy: 0.7480\n",
            "Epoch 933/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4622 - accuracy: 0.7678 - val_loss: 0.5272 - val_accuracy: 0.7480\n",
            "Epoch 934/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4622 - accuracy: 0.7739 - val_loss: 0.5279 - val_accuracy: 0.7561\n",
            "Epoch 935/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4629 - accuracy: 0.7678 - val_loss: 0.5276 - val_accuracy: 0.7561\n",
            "Epoch 936/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4620 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
            "Epoch 937/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4624 - accuracy: 0.7658 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
            "Epoch 938/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 939/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4622 - accuracy: 0.7678 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 940/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4617 - accuracy: 0.7678 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 941/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4621 - accuracy: 0.7699 - val_loss: 0.5277 - val_accuracy: 0.7561\n",
            "Epoch 942/1000\n",
            "491/491 [==============================] - 0s 42us/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
            "Epoch 943/1000\n",
            "491/491 [==============================] - 0s 51us/step - loss: 0.4618 - accuracy: 0.7658 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 944/1000\n",
            "491/491 [==============================] - 0s 48us/step - loss: 0.4615 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7480\n",
            "Epoch 945/1000\n",
            "491/491 [==============================] - 0s 46us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 946/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.5278 - val_accuracy: 0.7561\n",
            "Epoch 947/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4626 - accuracy: 0.7699 - val_loss: 0.5280 - val_accuracy: 0.7561\n",
            "Epoch 948/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4621 - accuracy: 0.7699 - val_loss: 0.5277 - val_accuracy: 0.7561\n",
            "Epoch 949/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4630 - accuracy: 0.7678 - val_loss: 0.5277 - val_accuracy: 0.7561\n",
            "Epoch 950/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4628 - accuracy: 0.7699 - val_loss: 0.5276 - val_accuracy: 0.7642\n",
            "Epoch 951/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4615 - accuracy: 0.7739 - val_loss: 0.5275 - val_accuracy: 0.7480\n",
            "Epoch 952/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4622 - accuracy: 0.7658 - val_loss: 0.5278 - val_accuracy: 0.7561\n",
            "Epoch 953/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.5279 - val_accuracy: 0.7561\n",
            "Epoch 954/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4617 - accuracy: 0.7739 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 955/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 956/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4613 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 957/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4617 - accuracy: 0.7658 - val_loss: 0.5281 - val_accuracy: 0.7561\n",
            "Epoch 958/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4622 - accuracy: 0.7739 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 959/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4623 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 960/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.5276 - val_accuracy: 0.7480\n",
            "Epoch 961/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4620 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 962/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4625 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 963/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4612 - accuracy: 0.7678 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 964/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4623 - accuracy: 0.7658 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 965/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4618 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 966/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4610 - accuracy: 0.7678 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 967/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4628 - accuracy: 0.7658 - val_loss: 0.5275 - val_accuracy: 0.7480\n",
            "Epoch 968/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4618 - accuracy: 0.7678 - val_loss: 0.5280 - val_accuracy: 0.7561\n",
            "Epoch 969/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.5279 - val_accuracy: 0.7561\n",
            "Epoch 970/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.5277 - val_accuracy: 0.7480\n",
            "Epoch 971/1000\n",
            "491/491 [==============================] - 0s 43us/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7480\n",
            "Epoch 972/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 973/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4612 - accuracy: 0.7678 - val_loss: 0.5280 - val_accuracy: 0.7561\n",
            "Epoch 974/1000\n",
            "491/491 [==============================] - 0s 40us/step - loss: 0.4616 - accuracy: 0.7739 - val_loss: 0.5276 - val_accuracy: 0.7480\n",
            "Epoch 975/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 976/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4611 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 977/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5275 - val_accuracy: 0.7561\n",
            "Epoch 978/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4611 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 979/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 980/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4609 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 981/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4609 - accuracy: 0.7678 - val_loss: 0.5274 - val_accuracy: 0.7561\n",
            "Epoch 982/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 983/1000\n",
            "491/491 [==============================] - 0s 39us/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 984/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4606 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 985/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4617 - accuracy: 0.7658 - val_loss: 0.5273 - val_accuracy: 0.7561\n",
            "Epoch 986/1000\n",
            "491/491 [==============================] - 0s 44us/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 987/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7480\n",
            "Epoch 988/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4611 - accuracy: 0.7678 - val_loss: 0.5278 - val_accuracy: 0.7561\n",
            "Epoch 989/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4613 - accuracy: 0.7780 - val_loss: 0.5277 - val_accuracy: 0.7561\n",
            "Epoch 990/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 991/1000\n",
            "491/491 [==============================] - 0s 38us/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 992/1000\n",
            "491/491 [==============================] - 0s 37us/step - loss: 0.4613 - accuracy: 0.7719 - val_loss: 0.5271 - val_accuracy: 0.7561\n",
            "Epoch 993/1000\n",
            "491/491 [==============================] - 0s 35us/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.5271 - val_accuracy: 0.7561\n",
            "Epoch 994/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4607 - accuracy: 0.7699 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 995/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5271 - val_accuracy: 0.7561\n",
            "Epoch 996/1000\n",
            "491/491 [==============================] - 0s 34us/step - loss: 0.4615 - accuracy: 0.7678 - val_loss: 0.5271 - val_accuracy: 0.7561\n",
            "Epoch 997/1000\n",
            "491/491 [==============================] - 0s 41us/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
            "Epoch 998/1000\n",
            "491/491 [==============================] - 0s 33us/step - loss: 0.4604 - accuracy: 0.7719 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
            "Epoch 999/1000\n",
            "491/491 [==============================] - 0s 32us/step - loss: 0.4610 - accuracy: 0.7699 - val_loss: 0.5274 - val_accuracy: 0.7480\n",
            "Epoch 1000/1000\n",
            "491/491 [==============================] - 0s 36us/step - loss: 0.4607 - accuracy: 0.7699 - val_loss: 0.5273 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bStZgFfZvxzq",
        "outputId": "a8f6b744-2b76-47d0-ea62-1bad607542e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "#Visualize the training loss and validation loss to see if the model is overfitting\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1VgO0yow2hM",
        "outputId": "cd3fae79-f2a6-44b7-987c-b4230a96ba36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "#Visualize the training accuracy and validation accuracy to see if the model is overfitting\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAyZEYT-xvVa",
        "outputId": "b33a0d4f-896b-4953-c0d6-cc3c98a9628f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#Make a prediction & print the actual values\n",
        "prediction = model.predict(X_test)\n",
        "prediction = [1 if Y>= 0.5 else 0 for Y in prediction]\n",
        "print(prediction)\n",
        "print(Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
            "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtKf7nrWyyBC",
        "outputId": "2a50abac-08e9-4958-a4cb-affe5987d556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Evaluate the model on the training dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_train)\n",
        "pred = [1 if Y>= 0.5 else 0 for Y in pred]\n",
        "print(classification_report(Y_train, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(Y_train, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(Y_train, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.87      0.83       398\n",
            "         1.0       0.71      0.57      0.63       216\n",
            "\n",
            "    accuracy                           0.77       614\n",
            "   macro avg       0.75      0.72      0.73       614\n",
            "weighted avg       0.76      0.77      0.76       614\n",
            "\n",
            "Confusion Matrix: \n",
            " [[347  51]\n",
            " [ 92 124]]\n",
            "\n",
            "Accuracy:  0.7671009771986971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cakm4ZrV0gKw",
        "outputId": "67f7fc3f-1e84-4d19-a865-2d6cc639cdd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Evaluate the model on the test dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "pred = [1 if Y>= 0.5 else 0 for Y in pred]\n",
        "print(classification_report(Y_test, pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(Y_test, pred))\n",
        "print()\n",
        "print('Accuracy: ', accuracy_score(Y_test, pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.86      0.85       102\n",
            "         1.0       0.71      0.67      0.69        52\n",
            "\n",
            "    accuracy                           0.80       154\n",
            "   macro avg       0.78      0.77      0.77       154\n",
            "weighted avg       0.80      0.80      0.80       154\n",
            "\n",
            "Confusion Matrix: \n",
            " [[88 14]\n",
            " [17 35]]\n",
            "\n",
            "Accuracy:  0.7987012987012987\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}